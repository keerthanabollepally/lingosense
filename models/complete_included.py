{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QgeSZYxh7gR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers indic-nlp-library indic-transliteration sentencepiece huggingface-hub regex\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uFS2i1vf7XSe",
        "outputId": "285b1263-e645-4c28-d077-86ac939f50f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.12/dist-packages (0.92)\n",
            "Requirement already satisfied: indic-transliteration in /usr/local/lib/python3.12/dist-packages (2.3.75)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (2.0.0)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (0.20.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Requirement already satisfied: roman in /usr/local/lib/python3.12/dist-packages (from indic-transliteration) (5.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.12/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer->indic-transliteration) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->indic-transliteration) (2.19.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic-transliteration) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bZWqLC6t63o1",
        "outputId": "1dfc0049-e744-4afe-a6e1-2d93448ef6ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "#############final(telugu , hindi, marathi, bengali ,tamil)\n",
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# =========================\n",
        "# Device Setup\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# Model Loading\n",
        "# =========================\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "# (Optional: Load IndicTrans if needed for Hindi/Tamil/Telugu and English bridging)\n",
        "\n",
        "# =========================\n",
        "# Settings (language parameters)\n",
        "# =========================\n",
        "LANG_CONFIG = {\n",
        "    \"hindi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡§ï‡§ï‡•ç‡§∑‡§æ\", \"meeting\": \"‡§¨‡•à‡§†‡§ï\", \"me\": \"‡§Æ‡•á‡§Ç\", \"after\": \"‡§¨‡§æ‡§¶\", \"ke\": \"‡§ï‡•á\", \"baad\": \"‡§¨‡§æ‡§¶\",\n",
        "            \"aana\": \"‡§Ü‡§®‡§æ\", \"hai\": \"‡§π‡•à\", \"mujhe\": \"‡§Æ‡•Å‡§ù‡•á\", \"please\": \"‡§ï‡•É‡§™‡§Ø‡§æ\", \"sir\": \"‡§∏‡§æ‡§π‡§¨\", \"madam\": \"‡§Æ‡•à‡§°‡§Æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"hin_Deva\",\n",
        "        \"normalizer\": \"hi\"\n",
        "    },\n",
        "    \"tamil\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"naan\": \"‡Æ®‡Ææ‡Æ©‡Øç\", \"nee\": \"‡Æ®‡ØÄ\", \"class\": \"‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç\", \"ku\": \"‡Æï‡Øç‡Æï‡ØÅ\", \"poganum\": \"‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"ponanum\": \"‡Æ™‡Øã‡Æµ‡Øá‡Æ©‡Øç\", \"varanum\": \"‡Æµ‡Æ∞‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"sollanum\": \"‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"pananum\": \"‡Æ™‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TAMIL,\n",
        "        \"lang_code_nllb\": \"tam_Taml\",\n",
        "        \"normalizer\": \"ta\"\n",
        "    },\n",
        "    \"telugu\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡∞§‡∞∞‡∞ó‡∞§‡∞ø\", \"vellali\": \"‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TELUGU,\n",
        "        \"lang_code_nllb\": \"tel_Telu\",\n",
        "        \"normalizer\": \"te\"\n",
        "    },\n",
        "    \"marathi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"tu\": \"‡§§‡•Ç\", \"tula\": \"‡§§‡•Å‡§≤‡§æ\", \"kasa\": \"‡§ï‡§∏‡§æ\", \"kasaa\": \"‡§ï‡§∏‡§æ\", \"aahe\": \"‡§Ü‡§π‡•á\", \"aahes\": \"‡§Ü‡§π‡•á‡§∏\", \"majha\": \"‡§Æ‡§æ‡§ù‡§æ\",\n",
        "            \"mazi\": \"‡§Æ‡§æ‡§ù‡•Ä\", \"maza\": \"‡§Æ‡§æ‡§ù‡§æ\", \"bandhu\": \"‡§≠‡§æ‡§ä\", \"mitra\": \"‡§Æ‡§ø‡§§‡•ç‡§∞\", \"aaj\": \"‡§Ü‡§ú\", \"udya\": \"‡§â‡§¶‡•ç‡§Ø‡§æ\",\n",
        "            \"school\": \"‡§∂‡§æ‡§≥‡§æ\", \"la\": \"‡§≤‡§æ\", \"nako\": \"‡§®‡§ï‡•ã\", \"karan\": \"‡§ï‡§æ‡§∞‡§£\", \"majha dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\",\n",
        "            \"maza dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\", \"bhet\": \"‡§≠‡•á‡§ü\", \"chhan\": \"‡§õ‡§æ‡§®\", \"movie\": \"‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü\",\n",
        "            \"pahila\": \"‡§™‡§æ‡§π‡§ø‡§≤‡§æ\", \"pahile\": \"‡§™‡§æ‡§π‡§ø‡§≤‡•á\", \"awesome\": \"‡§õ‡§æ‡§®\", \"mi\": \"‡§Æ‡•Ä\", \"jaato\": \"‡§ú‡§æ‡§§‡•ã\",\n",
        "            \"jatoy\": \"‡§ú‡§æ‡§§‡•ã\", \"nahi\": \"‡§®‡§æ‡§π‡•Ä\", \"aahe ka\": \"‡§Ü‡§π‡•á ‡§ï‡§æ\", \"dokyacha\": \"‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§ö‡§æ\",\n",
        "            \"dukh\": \"‡§¶‡•Å‡§ñ\", \"hota\": \"‡§π‡•ã‡§§‡§æ\", \"mala\": \"‡§Æ‡§≤‡§æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"mar_Deva\",\n",
        "        \"normalizer\": \"mr\"\n",
        "    },\n",
        "    \"bengali\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"ami\": \"‡¶Ü‡¶Æ‡¶ø\", \"tumi\": \"‡¶§‡ßÅ‡¶Æ‡¶ø\", \"tomar\": \"‡¶§‡ßã‡¶Æ‡¶æ‡¶∞\", \"ke\": \"‡¶ï‡ßá\",\n",
        "            \"sathe\": \"‡¶∏‡¶æ‡¶•‡ßá\", \"bhalo\": \"‡¶≠‡¶æ‡¶≤‡ßã\", \"jabo\": \"‡¶Ø‡¶æ‡¶¨‡ßã\", \"asche\": \"‡¶Ü‡¶∏‡ßá\",\n",
        "            \"korbo\": \"‡¶ï‡¶∞‡¶¨‡ßã\", \"amar\": \"‡¶Ü‡¶Æ‡¶æ‡¶∞\", \"kotha\": \"‡¶ï‡ßã‡¶•‡¶æ\", \"bari\": \"‡¶¨‡¶æ‡¶°‡¶º‡¶ø\",\n",
        "            \"achho\": \"‡¶Ü‡¶õ‡ßã\", \"ki\": \"‡¶ï‡¶ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.BENGALI,\n",
        "        \"lang_code_nllb\": \"ben_Beng\",\n",
        "        \"normalizer\": \"bn\"\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Core Functions (per language)\n",
        "# =========================\n",
        "\n",
        "def transliterate_roman_to_native(text: str, lang: str) -> str:\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    out_tokens = []\n",
        "    for tok in tokens:\n",
        "        if re.match(r\"^[A-Za-z]+$\", tok):\n",
        "            low = tok.lower()\n",
        "            mapped = config[\"code_mix_dict\"].get(low)\n",
        "            if mapped:\n",
        "                out_tokens.append(mapped)\n",
        "            else:\n",
        "                try:\n",
        "                    native = transliterate(tok, config[\"src_script\"], config[\"tgt_script\"])\n",
        "                    if re.search(r\"[A-Za-z]\", native):\n",
        "                        out_tokens.append(tok)\n",
        "                    else:\n",
        "                        out_tokens.append(native)\n",
        "                except Exception:\n",
        "                    out_tokens.append(tok)\n",
        "        else:\n",
        "            out_tokens.append(tok)\n",
        "    return \" \".join(out_tokens).strip()\n",
        "\n",
        "def normalize_native_text(text: str, lang: str) -> str:\n",
        "    normalizer = indic_normalize.IndicNormalizerFactory().get_normalizer(LANG_CONFIG[lang][\"normalizer\"])\n",
        "    normalized = normalizer.normalize(text)\n",
        "    # Add custom replacements per language, e.g., (\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\") for Hindi\n",
        "    if lang == \"hindi\":\n",
        "        normalized = normalized.replace(\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\").replace(\"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó\", \"‡§¨‡•à‡§†‡§ï\")\n",
        "    elif lang == \"bengali\":\n",
        "        normalized = normalized.replace(\"‡¶≠‡¶æ‡¶≤\", \"‡¶≠‡¶æ‡¶≤‡ßã\")\n",
        "    elif lang == \"marathi\":\n",
        "        normalized = normalized.replace(\"‡§õ‡•ç‡§π‡§æ‡§®\", \"‡§õ‡§æ‡§®\")\n",
        "        normalized = normalized.replace(\"\\u200c\", \"\").replace(\"\\u200b\", \"\")\n",
        "    return re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "def detect_code_mixed_words(text: str, lang: str):\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    return [tok for tok in tokens if tok.lower() in config[\"code_mix_dict\"] or re.match(r\"^[A-Za-z]+$\", tok)]\n",
        "\n",
        "# =========================\n",
        "# Translation (NLLB)\n",
        "# =========================\n",
        "\n",
        "def translate_nllb(text, src_lang, tgt_lang):\n",
        "    tokenizer_nllb.src_lang = src_lang\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_lang_id = tokenizer_nllb.convert_tokens_to_ids(tgt_lang)\n",
        "    generated = model_nllb.generate(**encoded, forced_bos_token_id=tgt_lang_id)\n",
        "    return tokenizer_nllb.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "# =========================\n",
        "# Combined Multilingual Pipeline\n",
        "# =========================\n",
        "\n",
        "def full_pipeline(input_text: str, input_lang: str, target_langs: list):\n",
        "    print(f\"\\nü™Ñ Step 0: Input Text: {input_text}\")\n",
        "\n",
        "    # Step 1: Roman ‚Üí Native Script\n",
        "    native_text = transliterate_roman_to_native(input_text, input_lang)\n",
        "    print(f\"üà∂ Step 1: After Transliteration: {native_text}\")\n",
        "\n",
        "    # Step 2: Detect code-mixed words\n",
        "    code_mix = detect_code_mixed_words(input_text, input_lang)\n",
        "    print(f\"üîç Step 2: Detected code-mixed words: {code_mix}\")\n",
        "\n",
        "    # Step 3: Normalization\n",
        "    normalized_native = normalize_native_text(native_text, input_lang)\n",
        "    print(f\"ü™∂ Step 3: Normalized Text: {normalized_native}\")\n",
        "\n",
        "    # Step 4: Native ‚Üí English\n",
        "    english_text = translate_nllb(normalized_native, LANG_CONFIG[input_lang][\"lang_code_nllb\"], \"eng_Latn\")\n",
        "    print(f\"üá¨üáß Step 4: English Translation: {english_text}\")\n",
        "\n",
        "    # Step 5: English ‚Üí Target Languages\n",
        "    translations = {LANG_CONFIG[input_lang][\"lang_code_nllb\"]: normalized_native, \"eng_Latn\": english_text}\n",
        "    print(\"\\nüåç Step 5: Translations to Other Languages:\")\n",
        "    for lang in target_langs:\n",
        "        lang_code = LANG_CONFIG[lang][\"lang_code_nllb\"]\n",
        "        translated_text = translate_nllb(english_text, \"eng_Latn\", lang_code)\n",
        "        translations[lang_code] = translated_text\n",
        "        print(f\"{lang_code}: {translated_text}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Multilingual translation pipeline complete!\")\n",
        "    return translations\n",
        "\n",
        "# =========================\n",
        "# Example Usage (single entry point)\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"mujhe class ke baad meeting me aana hai\"\n",
        "    INPUT_LANG = \"hindi\"\n",
        "    TARGET_LANGUAGES = [\"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"naan class ku poganum\"\n",
        "    INPUT_LANG = \"tamil\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fqUlL3b067NK",
        "outputId": "4dc7a109-7570-442a-b0a1-cb5304926a84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: naan class ku poganum\n",
            "üà∂ Step 1: After Transliteration: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\n",
            "üîç Step 2: Detected code-mixed words: ['naan', 'class', 'ku', 'poganum']\n",
            "ü™∂ Step 3: Normalized Text: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\n",
            "üá¨üáß Step 4: English Translation: I have to go to class.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ï‡•ç‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§æ ‡§π‡•à‡•§\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞§‡∞∞‡∞ó‡∞§‡∞ø ‡∞µ‡±Ü‡∞≥‡±ç‡∞≥‡∞æ‡∞≤‡∞ø.\n",
            "mar_Deva: ‡§Æ‡§≤‡§æ ‡§µ‡§∞‡•ç‡§ó‡§æ‡§§ ‡§ú‡§æ‡§Ø‡§ö‡§Ç ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá ‡¶Ø‡ßá‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"mi udya school la jaato nahi karan mala dokyacha dukh hota\"\n",
        "    INPUT_LANG = \"marathi\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"telugu\", \"tamil\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OKQh1p_O85W2",
        "outputId": "8d8d534a-e662-46ed-b665-318d99006869"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: mi udya school la jaato nahi karan mala dokyacha dukh hota\n",
            "üà∂ Step 1: After Transliteration: ‡§Æ‡•Ä ‡§â‡§¶‡•ç‡§Ø‡§æ ‡§∂‡§æ‡§≥‡§æ ‡§≤‡§æ ‡§ú‡§æ‡§§‡•ã ‡§®‡§æ‡§π‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡§≤‡§æ ‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§¶‡•Å‡§ñ ‡§π‡•ã‡§§‡§æ\n",
            "üîç Step 2: Detected code-mixed words: ['mi', 'udya', 'school', 'la', 'jaato', 'nahi', 'karan', 'mala', 'dokyacha', 'dukh', 'hota']\n",
            "ü™∂ Step 3: Normalized Text: ‡§Æ‡•Ä ‡§â‡§¶‡•ç‡§Ø‡§æ ‡§∂‡§æ‡§≥‡§æ ‡§≤‡§æ ‡§ú‡§æ‡§§‡•ã ‡§®‡§æ‡§π‡•Ä ‡§ï‡§æ‡§∞‡§£ ‡§Æ‡§≤‡§æ ‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§¶‡•Å‡§ñ ‡§π‡•ã‡§§‡§æ\n",
            "üá¨üáß Step 4: English Translation: I don't go to school tomorrow because I have a headache.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç ‡§ï‡§≤ ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡§æ‡§§‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Æ‡•Å‡§ù‡•á ‡§∏‡§ø‡§∞‡§¶‡§∞‡•ç‡§¶ ‡§π‡•à‡•§\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï ‡∞§‡∞≤‡∞®‡±ä‡∞™‡±ç‡∞™‡∞ø ‡∞é‡∞Ç‡∞¶‡±Å‡∞ï‡∞Ç‡∞ü‡±á ‡∞®‡±á‡∞®‡±Å ‡∞∞‡±á‡∞™‡±Å ‡∞™‡∞æ‡∞†‡∞∂‡∞æ‡∞≤‡∞ï‡±Å ‡∞µ‡±Ü‡∞≥‡±ç‡∞≥‡∞°‡∞Ç ‡∞≤‡±á‡∞¶‡±Å.\n",
            "tam_Taml: ‡Æé‡Æ©‡Æï‡Øç‡Æï‡ØÅ ‡Æ§‡Æ≤‡Øà‡Æµ‡Æ≤‡Æø ‡Æá‡Æ∞‡ØÅ‡Æ™‡Øç‡Æ™‡Æ§‡Ææ‡Æ≤‡Øç ‡Æ®‡Ææ‡Æ©‡Øç ‡Æ®‡Ææ‡Æ≥‡Øà ‡Æ™‡Æ≥‡Øç‡Æ≥‡Æø‡Æï‡Øç‡Æï‡ØÅ ‡Æö‡ØÜ‡Æ≤‡Øç‡Æ≤ ‡ÆÆ‡Ææ‡Æü‡Øç‡Æü‡Øá‡Æ©‡Øç.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶æ‡¶≤ ‡¶∏‡ßç‡¶ï‡ßÅ‡¶≤‡ßá ‡¶Ø‡¶æ‡¶á ‡¶®‡¶æ ‡¶ï‡¶æ‡¶∞‡¶£ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ ‡¶¨‡ßç‡¶Ø‡¶•‡¶æ ‡¶ï‡¶∞‡¶õ‡ßá‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"mi movie pahila ani to khup chhan hota\"\n",
        "    INPUT_LANG = \"marathi\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"telugu\", \"tamil\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dgjojHnv9Fmb",
        "outputId": "e584ce21-e7f3-44b5-eada-7ec140f34dd3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: mi movie pahila ani to khup chhan hota\n",
            "üà∂ Step 1: After Transliteration: ‡§Æ‡•Ä ‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü ‡§™‡§æ‡§π‡§ø‡§≤‡§æ ‡§Ö‡§®‡§ø ‡§§‡•ã ‡§ñ‡•Å‡§™‡•ç ‡§õ‡§æ‡§® ‡§π‡•ã‡§§‡§æ\n",
            "üîç Step 2: Detected code-mixed words: ['mi', 'movie', 'pahila', 'ani', 'to', 'khup', 'chhan', 'hota']\n",
            "ü™∂ Step 3: Normalized Text: ‡§Æ‡•Ä ‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü ‡§™‡§æ‡§π‡§ø‡§≤‡§æ ‡§Ö‡§®‡§ø ‡§§‡•ã ‡§ñ‡•Å‡§™‡•ç ‡§õ‡§æ‡§® ‡§π‡•ã‡§§‡§æ\n",
            "üá¨üáß Step 4: English Translation: I saw the movie and it was really cool.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç‡§®‡•á ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§¶‡•á‡§ñ‡•Ä ‡§î‡§∞ ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§•‡§æ‡•§\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞∏‡∞ø‡∞®‡∞ø‡∞Æ‡∞æ ‡∞ö‡±Ç‡∞∏‡∞ø‡∞Ç‡∞¶‡∞ø ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞Ö‡∞¶‡∞ø ‡∞®‡∞ø‡∞ú‡∞Ç‡∞ó‡∞æ ‡∞¨‡∞æ‡∞ó‡±Å‡∞Ç‡∞¶‡∞ø.\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æ™‡Æü‡ÆÆ‡Øç ‡Æ™‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§‡Øá‡Æ©‡Øç ‡ÆÖ‡Æ§‡ØÅ ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ∞‡ØÅ‡ÆÆ‡Øà‡ÆØ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡Æ§‡ØÅ.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶ø ‡¶Æ‡ßÅ‡¶≠‡¶ø‡¶ü‡¶æ ‡¶¶‡ßá‡¶ñ‡ßá‡¶õ‡¶ø, ‡¶ì‡¶ü‡¶æ ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶á ‡¶¶‡¶æ‡¶∞‡ßÅ‡¶£ ‡¶õ‡¶ø‡¶≤‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"ami tomar sathe jabo\"\n",
        "    INPUT_LANG = \"bengali\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"telugu\", \"marathi\", \"tamil\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4CMqusDV9f5G",
        "outputId": "ce3ac4b2-2bc2-47a5-f1ca-62bf8f689be0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: ami tomar sathe jabo\n",
            "üà∂ Step 1: After Transliteration: ‡¶Ü‡¶Æ‡¶ø ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Ø‡¶æ‡¶¨‡ßã\n",
            "üîç Step 2: Detected code-mixed words: ['ami', 'tomar', 'sathe', 'jabo']\n",
            "ü™∂ Step 3: Normalized Text: ‡¶Ü‡¶Æ‡¶ø ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Ø‡¶æ‡¶¨‡ßã\n",
            "üá¨üáß Step 4: English Translation: I'll go with you.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§∏‡§æ‡§• ‡§ú‡§æ‡§ä‡§Å‡§ó‡§æ.\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä‡∞§‡±ã ‡∞µ‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å.\n",
            "mar_Deva: ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ‡§¨‡§∞‡•ã‡§¨‡§∞ ‡§Ø‡•á‡§à‡§®.\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æ©‡Øç‡Æ©‡ØÅ‡Æü‡Æ©‡Øç ‡Æµ‡Æ∞‡ØÅ‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"oi din amar old school e gesilam\"\n",
        "    INPUT_LANG = \"bengali\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"telugu\", \"marathi\", \"tamil\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Og780hvS9uN3",
        "outputId": "b3717e23-6899-4d0e-a45f-6e97906205e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: oi din amar old school e gesilam\n",
            "üà∂ Step 1: After Transliteration: ‡¶ì‡¶á ‡¶¶‡¶ø‡¶®‡ßç ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ì‡¶≤‡ßç‡¶¶‡ßç ‡¶∏‡ßç‡¶ö‡ßÇ‡¶≤‡ßç ‡¶è ‡¶ó‡ßá‡¶∏‡¶ø‡¶≤‡¶Æ‡ßç\n",
            "üîç Step 2: Detected code-mixed words: ['oi', 'din', 'amar', 'old', 'school', 'e', 'gesilam']\n",
            "ü™∂ Step 3: Normalized Text: ‡¶ì‡¶á ‡¶¶‡¶ø‡¶®‡ßç ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ì‡¶≤‡ßç‡¶¶‡ßç ‡¶∏‡ßç‡¶ö‡ßÇ‡¶≤‡ßç ‡¶è ‡¶ó‡ßá‡¶∏‡¶ø‡¶≤‡¶Æ‡ßç\n",
            "üá¨üáß Step 4: English Translation: I was in my old school that day.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç ‡§â‡§∏ ‡§¶‡§ø‡§® ‡§Ö‡§™‡§®‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§Æ‡•á‡§Ç ‡§•‡§æ‡•§\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞®‡∞æ ‡∞™‡∞æ‡∞§ ‡∞™‡∞æ‡∞†‡∞∂‡∞æ‡∞≤‡∞≤‡±ã ‡∞Ü ‡∞∞‡±ã‡∞ú‡±Å.\n",
            "mar_Deva: ‡§Æ‡•Ä ‡§§‡•ç‡§Ø‡§æ ‡§¶‡§ø‡§µ‡§∂‡•Ä ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§ú‡•Å‡§®‡•ç‡§Ø‡§æ ‡§∂‡§æ‡§≥‡•á‡§§ ‡§π‡•ã‡§§‡•ã.\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æé‡Æ©‡Øç ‡Æ™‡Æ¥‡Øà‡ÆØ ‡Æ™‡Æ≥‡Øç‡Æ≥‡Æø‡ÆØ‡Æø‡Æ≤‡Øç ‡ÆÖ‡Æ©‡Øç‡Æ±‡ØÅ ‡Æá‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡Øá‡Æ©‡Øç.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"mana next segment sweet and snacks\"\n",
        "    INPUT_LANG = \"telugu\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"bengali\", \"marathi\", \"tamil\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bfWN0cW098VL",
        "outputId": "6ec7d345-cecb-459c-8ba7-505a40a5c9e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: mana next segment sweet and snacks\n",
            "üà∂ Step 1: After Transliteration: ‡∞Æ‡∞® ‡∞®‡±á‡∞ï‡±ç‡∞∑‡±ç‡∞§‡±ç ‡∞∏‡±á‡∞ó‡±ç‡∞Æ‡±á‡∞®‡±ç‡∞§‡±ç ‡∞∏‡±ç‡∞µ‡±Ä‡∞§‡±ç ‡∞Ö‡∞®‡±ç‡∞¶‡±ç ‡∞∏‡±ç‡∞®‡∞ö‡±ç‡∞ï‡±ç‡∞∏‡±ç\n",
            "üîç Step 2: Detected code-mixed words: ['mana', 'next', 'segment', 'sweet', 'and', 'snacks']\n",
            "ü™∂ Step 3: Normalized Text: ‡∞Æ‡∞® ‡∞®‡±á‡∞ï‡±ç‡∞∑‡±ç‡∞§‡±ç ‡∞∏‡±á‡∞ó‡±ç‡∞Æ‡±á‡∞®‡±ç‡∞§‡±ç ‡∞∏‡±ç‡∞µ‡±Ä‡∞§‡±ç ‡∞Ö‡∞®‡±ç‡∞¶‡±ç ‡∞∏‡±ç‡∞®‡∞ö‡±ç‡∞ï‡±ç‡∞∏‡±ç\n",
            "üá¨üáß Step 4: English Translation: Our next segment is Sweet and Snacks.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§π‡§Æ‡§æ‡§∞‡§æ ‡§Ö‡§ó‡§≤‡§æ ‡§ñ‡§Ç‡§° ‡§Æ‡•Ä‡§†‡§æ ‡§î‡§∞ ‡§∏‡•ç‡§®‡•à‡§ï‡•ç‡§∏ ‡§π‡•à‡•§\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶∏‡ßá‡¶ó‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶π‡¶≤ ‡¶Æ‡¶ø‡¶∑‡ßç‡¶ü‡¶ø ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßç‡¶®‡ßç‡¶Ø‡¶æ‡¶ï‡¶∏‡•§\n",
            "mar_Deva: ‡§Ü‡§Æ‡§ö‡§æ ‡§™‡•Å‡§¢‡§ö‡§æ ‡§≠‡§æ‡§ó ‡§Ü‡§π‡•á ‡§Æ‡§ø‡§†‡§æ‡§à ‡§Ü‡§£‡§ø ‡§∏‡•ç‡§®‡•Ö‡§ï‡•ç‡§∏.\n",
            "tam_Taml: ‡ÆÖ‡Æü‡ØÅ‡Æ§‡Øç‡Æ§ ‡Æ™‡Æï‡ØÅ‡Æ§‡Æø ‡Æá‡Æ©‡Æø‡Æ™‡Øç‡Æ™‡ØÅ ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æ∏‡Øç‡Æ©‡Ææ‡Æï‡Øç‡Æ∏‡Øç.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set source and target languages as desired\n",
        "    INPUT_SENTENCE = \"onions ni deep fry cheyyali color change ayyye varaku\"\n",
        "    INPUT_LANG = \"telugu\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"bengali\", \"marathi\", \"tamil\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vO4FF5CI-RUj",
        "outputId": "ac40c67f-b949-4e87-9a58-f4a41d056355"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: onions ni deep fry cheyyali color change ayyye varaku\n",
            "üà∂ Step 1: After Transliteration: ‡∞ì‡∞®‡∞ø‡∞ì‡∞®‡±ç‡∞∏‡±ç ‡∞®‡∞ø ‡∞¶‡±Ä‡∞™‡±ç fry ‡∞ö‡±á‡∞Ø‡±ç‡∞Ø‡∞≤‡∞ø ‡∞ö‡±ã‡∞≤‡±ã‡∞∞‡±ç ‡∞ö‡∞®‡±ç‡∞ó‡±á ‡∞Ö‡∞Ø‡±ç‡∞Ø‡±ç‡∞Ø‡±á ‡∞µ‡∞∞‡∞ï‡±Å\n",
            "üîç Step 2: Detected code-mixed words: ['onions', 'ni', 'deep', 'fry', 'cheyyali', 'color', 'change', 'ayyye', 'varaku']\n",
            "ü™∂ Step 3: Normalized Text: ‡∞ì‡∞®‡∞ø‡∞ì‡∞®‡±ç‡∞∏‡±ç ‡∞®‡∞ø ‡∞¶‡±Ä‡∞™‡±ç fry ‡∞ö‡±á‡∞Ø‡±ç‡∞Ø‡∞≤‡∞ø ‡∞ö‡±ã‡∞≤‡±ã‡∞∞‡±ç ‡∞ö‡∞®‡±ç‡∞ó‡±á ‡∞Ö‡∞Ø‡±ç‡∞Ø‡±ç‡∞Ø‡±á ‡∞µ‡∞∞‡∞ï‡±Å\n",
            "üá¨üáß Step 4: English Translation: The onions are deep fried until the choleur changes.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§™‡•ç‡§Ø‡§æ‡§ú ‡§ï‡•ã ‡§§‡§¨ ‡§§‡§ï ‡§§‡§ø‡§≤‡§ï‡§∞‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§¨ ‡§§‡§ï ‡§ï‡§ø ‡§ö‡•å‡§∞ ‡§¨‡§¶‡§≤ ‡§® ‡§ú‡§æ‡§è‡•§\n",
            "ben_Beng: ‡¶ö‡¶ø‡¶®‡¶ø‡¶∞ ‡¶∞‡¶ô ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶®‡¶æ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ö‡¶ø‡¶®‡¶ø‡¶ü‡¶ø ‡¶ó‡¶≠‡ßÄ‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶≠‡¶æ‡¶ú‡¶æ ‡¶•‡¶æ‡¶ï‡ßá‡•§\n",
            "mar_Deva: ‡§ö‡§π‡§æ‡§ö‡•Ä ‡§∞‡§Ç‡§ó ‡§¨‡§¶‡§≤‡•á‡§™‡§∞‡•ç‡§Ø‡§Ç‡§§ ‡§§‡•Ä ‡§§‡§≥‡§≤‡•á‡§≤‡•Ä ‡§Ö‡§∏‡§§‡•á.\n",
            "tam_Taml: ‡ÆÆ‡Æø‡Æ≥‡Æï‡ØÅ‡Æï‡Æ≥‡Øç ‡Æï‡Øä‡Æ≤‡Æ∞‡Øç ‡ÆÆ‡Ææ‡Æ±‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Æ∞‡Øà ‡Æµ‡Æ±‡ØÅ‡Æ§‡Øç‡Æ§‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# =========================\n",
        "# Device Setup\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# Model Loading\n",
        "# =========================\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "# =========================\n",
        "# Settings (language parameters)\n",
        "# =========================\n",
        "LANG_CONFIG = {\n",
        "    \"hindi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡§ï‡§ï‡•ç‡§∑‡§æ\", \"meeting\": \"‡§¨‡•à‡§†‡§ï\", \"me\": \"‡§Æ‡•á‡§Ç\", \"after\": \"‡§¨‡§æ‡§¶\", \"ke\": \"‡§ï‡•á\", \"baad\": \"‡§¨‡§æ‡§¶\",\n",
        "            \"aana\": \"‡§Ü‡§®‡§æ\", \"hai\": \"‡§π‡•à\", \"mujhe\": \"‡§Æ‡•Å‡§ù‡•á\", \"please\": \"‡§ï‡•É‡§™‡§Ø‡§æ\", \"sir\": \"‡§∏‡§æ‡§π‡§¨\", \"madam\": \"‡§Æ‡•à‡§°‡§Æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"hin_Deva\",\n",
        "        \"normalizer\": \"hi\"\n",
        "    },\n",
        "    \"tamil\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"naan\": \"‡Æ®‡Ææ‡Æ©‡Øç\", \"nee\": \"‡Æ®‡ØÄ\", \"class\": \"‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç\", \"ku\": \"‡Æï‡Øç‡Æï‡ØÅ\", \"poganum\": \"‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"ponanum\": \"‡Æ™‡Øã‡Æµ‡Øá‡Æ©‡Øç\", \"varanum\": \"‡Æµ‡Æ∞‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"sollanum\": \"‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"pananum\": \"‡Æ™‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TAMIL,\n",
        "        \"lang_code_nllb\": \"tam_Taml\",\n",
        "        \"normalizer\": \"ta\"\n",
        "    },\n",
        "    \"telugu\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡∞§‡∞∞‡∞ó‡∞§‡∞ø\", \"vellali\": \"‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TELUGU,\n",
        "        \"lang_code_nllb\": \"tel_Telu\",\n",
        "        \"normalizer\": \"te\"\n",
        "    },\n",
        "    \"marathi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"tu\": \"‡§§‡•Ç\", \"tula\": \"‡§§‡•Å‡§≤‡§æ\", \"kasa\": \"‡§ï‡§∏‡§æ\", \"kasaa\": \"‡§ï‡§∏‡§æ\", \"aahe\": \"‡§Ü‡§π‡•á\", \"aahes\": \"‡§Ü‡§π‡•á‡§∏\", \"majha\": \"‡§Æ‡§æ‡§ù‡§æ\",\n",
        "            \"mazi\": \"‡§Æ‡§æ‡§ù‡•Ä\", \"maza\": \"‡§Æ‡§æ‡§ù‡§æ\", \"bandhu\": \"‡§≠‡§æ‡§ä\", \"mitra\": \"‡§Æ‡§ø‡§§‡•ç‡§∞\", \"aaj\": \"‡§Ü‡§ú\", \"udya\": \"‡§â‡§¶‡•ç‡§Ø‡§æ\",\n",
        "            \"school\": \"‡§∂‡§æ‡§≥‡§æ\", \"la\": \"‡§≤‡§æ\", \"nako\": \"‡§®‡§ï‡•ã\", \"karan\": \"‡§ï‡§æ‡§∞‡§£\", \"majha dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\",\n",
        "            \"maza dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\", \"bhet\": \"‡§≠‡•á‡§ü\", \"chhan\": \"‡§õ‡§æ‡§®\", \"movie\": \"‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü\",\n",
        "            \"pahila\": \"‡§™‡§æ‡§π‡§ø‡§≤‡§æ\", \"pahile\": \"‡§™‡§æ‡§π‡§ø‡§≤‡•á\", \"awesome\": \"‡§õ‡§æ‡§®\", \"mi\": \"‡§Æ‡•Ä\", \"jaato\": \"‡§ú‡§æ‡§§‡•ã\",\n",
        "            \"jatoy\": \"‡§ú‡§æ‡§§‡•ã\", \"nahi\": \"‡§®‡§æ‡§π‡•Ä\", \"aahe ka\": \"‡§Ü‡§π‡•á ‡§ï‡§æ\", \"dokyacha\": \"‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§ö‡§æ\",\n",
        "            \"dukh\": \"‡§¶‡•Å‡§ñ\", \"hota\": \"‡§π‡•ã‡§§‡§æ\", \"mala\": \"‡§Æ‡§≤‡§æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"mar_Deva\",\n",
        "        \"normalizer\": \"mr\"\n",
        "    },\n",
        "    \"bengali\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"ami\": \"‡¶Ü‡¶Æ‡¶ø\", \"tumi\": \"‡¶§‡ßÅ‡¶Æ‡¶ø\", \"tomar\": \"‡¶§‡ßã‡¶Æ‡¶æ‡¶∞\", \"ke\": \"‡¶ï‡ßá\",\n",
        "            \"sathe\": \"‡¶∏‡¶æ‡¶•‡ßá\", \"bhalo\": \"‡¶≠‡¶æ‡¶≤‡ßã\", \"jabo\": \"‡¶Ø‡¶æ‡¶¨‡ßã\", \"asche\": \"‡¶Ü‡¶∏‡ßá\",\n",
        "            \"korbo\": \"‡¶ï‡¶∞‡¶¨‡ßã\", \"amar\": \"‡¶Ü‡¶Æ‡¶æ‡¶∞\", \"kotha\": \"‡¶ï‡ßã‡¶•‡¶æ\", \"bari\": \"‡¶¨‡¶æ‡¶°‡¶º‡¶ø\",\n",
        "            \"achho\": \"‡¶Ü‡¶õ‡ßã\", \"ki\": \"‡¶ï‡¶ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.BENGALI,\n",
        "        \"lang_code_nllb\": \"ben_Beng\",\n",
        "        \"normalizer\": \"bn\"\n",
        "    },\n",
        "    \"malayalam\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"nee\": \"‡¥®‡µÄ\", \"lunch\": \"‡¥≤‡¥û‡µç‡¥ö‡µç\", \"eppozha\": \"‡¥é‡¥™‡µç‡¥™‡µã‡¥¥‡¥æ\", \"kazhicha\": \"‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö\",\n",
        "            \"innale\": \"‡¥á‡¥®‡µç‡¥®‡¥≤‡µÜ\", \"padam\": \"‡¥™‡¥ü‡¥Ç\", \"super\": \"‡¥∏‡µÇ‡¥™‡µç‡¥™‡µº\", \"family\": \"‡¥ï‡µÅ‡¥ü‡µÅ‡¥Ç‡¥¨‡¥Ç\",\n",
        "            \"meet\": \"‡¥Æ‡µÄ‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç\", \"poyi\": \"‡¥™‡µã‡¥Ø‡¥ø\", \"kananam\": \"‡¥ï‡¥æ‡¥£‡¥£‡¥Ç\", \"abhinayam\": \"‡¥Ö‡¥≠‡¥ø‡¥®‡¥Ø‡¥Ç\",\n",
        "            \"avanda\": \"‡¥Ö‡¥µ‡¥®‡µç‡¥±‡µÜ\", \"veettil\": \"‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ\", \"etthiyattu\": \"‡¥é‡¥§‡µç‡¥§‡¥ø‡¥Ø‡¥ø‡¥ü‡µç‡¥ü‡µç\",\n",
        "            \"call\": \"‡¥ï‡µã‡µæ\", \"namukku\": \"‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ\", \"today\": \"‡¥á‡¥®‡µç‡¥®‡µç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.MALAYALAM,\n",
        "        \"lang_code_nllb\": \"mal_Mlym\",\n",
        "        \"normalizer\": \"ml\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Core Functions (per language)\n",
        "# =========================\n",
        "\n",
        "def transliterate_roman_to_native(text: str, lang: str) -> str:\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    out_tokens = []\n",
        "    for tok in tokens:\n",
        "        if re.match(r\"^[A-Za-z]+$\", tok):\n",
        "            low = tok.lower()\n",
        "            mapped = config[\"code_mix_dict\"].get(low)\n",
        "            if mapped:\n",
        "                out_tokens.append(mapped)\n",
        "            else:\n",
        "                try:\n",
        "                    native = transliterate(tok, config[\"src_script\"], config[\"tgt_script\"])\n",
        "                    if re.search(r\"[A-Za-z]\", native):\n",
        "                        out_tokens.append(tok)\n",
        "                    else:\n",
        "                        out_tokens.append(native)\n",
        "                except Exception:\n",
        "                    out_tokens.append(tok)\n",
        "        else:\n",
        "            out_tokens.append(tok)\n",
        "    return \" \".join(out_tokens).strip()\n",
        "\n",
        "def normalize_native_text(text: str, lang: str) -> str:\n",
        "    normalizer = indic_normalize.IndicNormalizerFactory().get_normalizer(LANG_CONFIG[lang][\"normalizer\"])\n",
        "    normalized = normalizer.normalize(text)\n",
        "    # Add custom replacements per language as needed:\n",
        "    if lang == \"hindi\":\n",
        "        normalized = normalized.replace(\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\").replace(\"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó\", \"‡§¨‡•à‡§†‡§ï\")\n",
        "    elif lang == \"bengali\":\n",
        "        normalized = normalized.replace(\"‡¶≠‡¶æ‡¶≤\", \"‡¶≠‡¶æ‡¶≤‡ßã\")\n",
        "    elif lang == \"marathi\":\n",
        "        normalized = normalized.replace(\"‡§õ‡•ç‡§π‡§æ‡§®\", \"‡§õ‡§æ‡§®\").replace(\"\\u200c\", \"\").replace(\"\\u200b\", \"\")\n",
        "    return re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "def detect_code_mixed_words(text: str, lang: str):\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    return [tok for tok in tokens if tok.lower() in config[\"code_mix_dict\"] or re.match(r\"^[A-Za-z]+$\", tok)]\n",
        "\n",
        "# =========================\n",
        "# Translation (NLLB)\n",
        "# =========================\n",
        "\n",
        "def translate_nllb(text, src_lang, tgt_lang):\n",
        "    tokenizer_nllb.src_lang = src_lang\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_lang_id = tokenizer_nllb.convert_tokens_to_ids(tgt_lang)\n",
        "    generated = model_nllb.generate(**encoded, forced_bos_token_id=tgt_lang_id)\n",
        "    return tokenizer_nllb.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "# =========================\n",
        "# Combined Multilingual Pipeline\n",
        "# =========================\n",
        "\n",
        "def full_pipeline(input_text: str, input_lang: str, target_langs: list):\n",
        "    print(f\"\\nü™Ñ Step 0: Input Text: {input_text}\")\n",
        "\n",
        "    # Step 1: Roman ‚Üí Native Script\n",
        "    native_text = transliterate_roman_to_native(input_text, input_lang)\n",
        "    print(f\"üà∂ Step 1: After Transliteration: {native_text}\")\n",
        "\n",
        "    # Step 2: Detect code-mixed words\n",
        "    code_mix = detect_code_mixed_words(input_text, input_lang)\n",
        "    print(f\"üîç Step 2: Detected code-mixed words: {code_mix}\")\n",
        "\n",
        "    # Step 3: Normalization\n",
        "    normalized_native = normalize_native_text(native_text, input_lang)\n",
        "    print(f\"ü™∂ Step 3: Normalized Text: {normalized_native}\")\n",
        "\n",
        "    # Step 4: Native ‚Üí English\n",
        "    english_text = translate_nllb(normalized_native, LANG_CONFIG[input_lang][\"lang_code_nllb\"], \"eng_Latn\")\n",
        "    print(f\"üá¨üáß Step 4: English Translation: {english_text}\")\n",
        "\n",
        "    # Step 5: English ‚Üí Target Languages\n",
        "    translations = {LANG_CONFIG[input_lang][\"lang_code_nllb\"]: normalized_native, \"eng_Latn\": english_text}\n",
        "    print(\"\\nüåç Step 5: Translations to Other Languages:\")\n",
        "    for lang in target_langs:\n",
        "        lang_code = LANG_CONFIG[lang][\"lang_code_nllb\"]\n",
        "        translated_text = translate_nllb(english_text, \"eng_Latn\", lang_code)\n",
        "        translations[lang_code] = translated_text\n",
        "        print(f\"{lang_code}: {translated_text}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Multilingual translation pipeline complete!\")\n",
        "    return translations\n",
        "\n",
        "# =========================\n",
        "# Example Usage (single entry point)\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # For Malayalam example:\n",
        "    INPUT_SENTENCE = \"nee lunch eppozha kazhicha?\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zG4f0Q7T-i5y",
        "outputId": "3b44c989-7583-4c3c-d491-3c6ae551c0a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: nee lunch eppozha kazhicha?\n",
            "üà∂ Step 1: After Transliteration: ‡¥®‡µÄ ‡¥≤‡¥û‡µç‡¥ö‡µç ‡¥é‡¥™‡µç‡¥™‡µã‡¥¥‡¥æ ‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö ?\n",
            "üîç Step 2: Detected code-mixed words: ['nee', 'lunch', 'eppozha', 'kazhicha']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥®‡µÄ ‡¥≤‡¥û‡µç‡¥ö‡µç ‡¥é‡¥™‡µç‡¥™‡µã‡¥¥‡¥æ ‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö ?\n",
            "üá¨üáß Step 4: English Translation: When did you have lunch?\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Ü‡§™‡§®‡•á ‡§ï‡§¨ ‡§¶‡•ã‡§™‡§π‡§∞ ‡§ï‡§æ ‡§≠‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ?\n",
            "tam_Taml: ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ§‡Æø‡ÆØ ‡Æâ‡Æ£‡Æµ‡ØÅ ‡Æé‡Æ™‡Øç‡Æ™‡Øã‡Æ§‡ØÅ ‡Æö‡Ææ‡Æ™‡Øç‡Æ™‡Æø‡Æü‡Øç‡Æü‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Øç?\n",
            "tel_Telu: ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞≠‡±ã‡∞ú‡∞®‡∞Ç ‡∞ö‡±á‡∞∏‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å?\n",
            "mar_Deva: ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡§ß‡•Ä ‡§≤‡§Ç‡§ö ‡§ï‡•á‡§≤‡§æ?\n",
            "ben_Beng: ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ï‡¶ñ‡¶® ‡¶≤‡¶æ‡¶û‡ßç‡¶ö ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡¶≤‡ßá?\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # For Malayalam example:\n",
        "    INPUT_SENTENCE = \"ee weekend namukku trip plan cheyyam\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0XAH7Qwk--as",
        "outputId": "75a23cdd-d0c5-4e81-a403-c90d2a2ac977"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: ee weekend namukku trip plan cheyyam\n",
            "üà∂ Step 1: After Transliteration: ‡¥à ‡¥µ‡µÄ‡¥ï‡µá‡¥®‡µç‡¥¶‡µç ‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ ‡¥§‡µç‡¥∞‡¥ø‡¥™‡µç ‡¥™‡µç‡¥≤‡¥®‡µç ‡¥ö‡µá‡¥Ø‡µç‡¥Ø‡¥Æ‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['ee', 'weekend', 'namukku', 'trip', 'plan', 'cheyyam']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥à ‡¥µ‡µÄ‡¥ï‡µá‡¥®‡µç‡¥¶‡µç ‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ ‡¥§‡µç‡¥∞‡¥ø‡¥™‡µç ‡¥™‡µç‡¥≤‡¥®‡µç ‡¥ö‡µá‡¥Ø‡µç‡¥Ø‡¥Æ‡µç\n",
            "üá¨üáß Step 4: English Translation: We're going to have a trip this weekend.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§π‡§Æ ‡§á‡§∏ ‡§∏‡§™‡•ç‡§§‡§æ‡§π ‡§ï‡•á ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§ï‡§∞‡§®‡•á ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç.\n",
            "tam_Taml: ‡Æá‡Æ®‡Øç‡Æ§ ‡Æµ‡Ææ‡Æ∞ ‡Æá‡Æ±‡ØÅ‡Æ§‡Æø‡ÆØ‡Æø‡Æ≤‡Øç ‡Æ®‡Ææ‡ÆÆ‡Øç ‡Æí‡Æ∞‡ØÅ ‡Æ™‡ÆØ‡Æ£‡ÆÆ‡Øç ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ ‡Æ™‡Øã‡Æï‡Æø‡Æ±‡Øã‡ÆÆ‡Øç.\n",
            "tel_Telu: ‡∞Æ‡±á‡∞Æ‡±Å ‡∞à ‡∞µ‡∞æ‡∞∞‡∞æ‡∞Ç‡∞§‡∞Ç‡∞≤‡±ã ‡∞í‡∞ï ‡∞Ø‡∞æ‡∞§‡±ç‡∞∞ ‡∞â‡∞Ç‡∞ü‡±Å‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§Ø‡§æ ‡§Ü‡§†‡§µ‡§°‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§∂‡•á‡§µ‡§ü‡§ö‡§æ ‡§™‡•ç‡§∞‡§µ‡§æ‡§∏ ‡§ï‡§∞‡§£‡§æ‡§∞ ‡§Ü‡§π‡•ã‡§§.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶è‡¶á ‡¶∏‡¶™‡ßç‡¶§‡¶æ‡¶π‡¶æ‡¶®‡ßç‡¶§‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≠‡ßç‡¶∞‡¶Æ‡¶£ ‡¶ï‡¶∞‡¶§‡ßá ‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡¶ø‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # For Malayalam example:\n",
        "    INPUT_SENTENCE = \"new phone review kandittu veendum think cheyyam\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8ttrgLh0_TrN",
        "outputId": "fdd57ca4-ed4a-42b9-adb8-4886a4dd0d29"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: new phone review kandittu veendum think cheyyam\n",
            "üà∂ Step 1: After Transliteration: ‡¥®‡µá‡¥µ‡µç ‡¥´‡µã‡¥®‡µá ‡¥∞‡µá‡¥µ‡¥ø‡¥è‡¥µ‡µç ‡¥ï‡¥®‡µç‡¥¶‡¥ø‡¥§‡µç‡¥§‡µÅ ‡¥µ‡µÄ‡¥®‡µç‡¥¶‡µÅ‡¥Æ‡µç ‡¥•‡¥ø‡¥®‡µç‡¥ï‡µç ‡¥ö‡µá‡¥Ø‡µç‡¥Ø‡¥Æ‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['new', 'phone', 'review', 'kandittu', 'veendum', 'think', 'cheyyam']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥®‡µá‡¥µ‡µç ‡¥´‡µã‡¥®‡µá ‡¥∞‡µá‡¥µ‡¥ø‡¥è‡¥µ‡µç ‡¥ï‡¥®‡µç‡¥¶‡¥ø‡¥§‡µç‡¥§‡µÅ ‡¥µ‡µÄ‡¥®‡µç‡¥¶‡µÅ‡¥Æ‡µç ‡¥•‡¥ø‡¥®‡µç‡¥ï‡µç ‡¥ö‡µá‡¥Ø‡µç‡¥Ø‡¥Æ‡µç\n",
            "üá¨üáß Step 4: English Translation: I'm not going to say anything.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç ‡§ï‡•Å‡§õ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§π‡•Ç‡§Ç‡§ó‡§æ‡•§\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æé‡Æ§‡ØÅ‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æö‡Øä‡Æ≤‡Øç‡Æ≤ ‡Æ™‡Øã‡Æµ‡Æ§‡Æø‡Æ≤‡Øç‡Æ≤‡Øà.\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞è‡∞Æ‡±Ä ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞®‡±Å.\n",
            "mar_Deva: ‡§Æ‡•Ä ‡§ï‡§æ‡§π‡•Ä‡§π‡•Ä ‡§¨‡•ã‡§≤‡§£‡§æ‡§∞ ‡§®‡§æ‡§π‡•Ä.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶ø ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶¨‡¶≤‡¶¨ ‡¶®‡¶æ‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################malayalam working fine\n",
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# =========================\n",
        "# Device Setup\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# Model Loading\n",
        "# =========================\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "# =========================\n",
        "# Settings (language parameters)\n",
        "# =========================\n",
        "LANG_CONFIG = {\n",
        "    \"hindi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡§ï‡§ï‡•ç‡§∑‡§æ\", \"meeting\": \"‡§¨‡•à‡§†‡§ï\", \"me\": \"‡§Æ‡•á‡§Ç\", \"after\": \"‡§¨‡§æ‡§¶\", \"ke\": \"‡§ï‡•á\", \"baad\": \"‡§¨‡§æ‡§¶\",\n",
        "            \"aana\": \"‡§Ü‡§®‡§æ\", \"hai\": \"‡§π‡•à\", \"mujhe\": \"‡§Æ‡•Å‡§ù‡•á\", \"please\": \"‡§ï‡•É‡§™‡§Ø‡§æ\", \"sir\": \"‡§∏‡§æ‡§π‡§¨\", \"madam\": \"‡§Æ‡•à‡§°‡§Æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"hin_Deva\",\n",
        "        \"normalizer\": \"hi\"\n",
        "    },\n",
        "    \"tamil\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"naan\": \"‡Æ®‡Ææ‡Æ©‡Øç\", \"nee\": \"‡Æ®‡ØÄ\", \"class\": \"‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç\", \"ku\": \"‡Æï‡Øç‡Æï‡ØÅ\", \"poganum\": \"‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"ponanum\": \"‡Æ™‡Øã‡Æµ‡Øá‡Æ©‡Øç\", \"varanum\": \"‡Æµ‡Æ∞‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"sollanum\": \"‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"pananum\": \"‡Æ™‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TAMIL,\n",
        "        \"lang_code_nllb\": \"tam_Taml\",\n",
        "        \"normalizer\": \"ta\"\n",
        "    },\n",
        "    \"telugu\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡∞§‡∞∞‡∞ó‡∞§‡∞ø\", \"vellali\": \"‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TELUGU,\n",
        "        \"lang_code_nllb\": \"tel_Telu\",\n",
        "        \"normalizer\": \"te\"\n",
        "    },\n",
        "    \"marathi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"tu\": \"‡§§‡•Ç\", \"tula\": \"‡§§‡•Å‡§≤‡§æ\", \"kasa\": \"‡§ï‡§∏‡§æ\", \"kasaa\": \"‡§ï‡§∏‡§æ\", \"aahe\": \"‡§Ü‡§π‡•á\", \"aahes\": \"‡§Ü‡§π‡•á‡§∏\", \"majha\": \"‡§Æ‡§æ‡§ù‡§æ\",\n",
        "            \"mazi\": \"‡§Æ‡§æ‡§ù‡•Ä\", \"maza\": \"‡§Æ‡§æ‡§ù‡§æ\", \"bandhu\": \"‡§≠‡§æ‡§ä\", \"mitra\": \"‡§Æ‡§ø‡§§‡•ç‡§∞\", \"aaj\": \"‡§Ü‡§ú\", \"udya\": \"‡§â‡§¶‡•ç‡§Ø‡§æ\",\n",
        "            \"school\": \"‡§∂‡§æ‡§≥‡§æ\", \"la\": \"‡§≤‡§æ\", \"nako\": \"‡§®‡§ï‡•ã\", \"karan\": \"‡§ï‡§æ‡§∞‡§£\", \"majha dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\",\n",
        "            \"maza dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\", \"bhet\": \"‡§≠‡•á‡§ü\", \"chhan\": \"‡§õ‡§æ‡§®\", \"movie\": \"‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü\",\n",
        "            \"pahila\": \"‡§™‡§æ‡§π‡§ø‡§≤‡§æ\", \"pahile\": \"‡§™‡§æ‡§π‡§ø‡§≤‡•á\", \"awesome\": \"‡§õ‡§æ‡§®\", \"mi\": \"‡§Æ‡•Ä\", \"jaato\": \"‡§ú‡§æ‡§§‡•ã\",\n",
        "            \"jatoy\": \"‡§ú‡§æ‡§§‡•ã\", \"nahi\": \"‡§®‡§æ‡§π‡•Ä\", \"aahe ka\": \"‡§Ü‡§π‡•á ‡§ï‡§æ\", \"dokyacha\": \"‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§ö‡§æ\",\n",
        "            \"dukh\": \"‡§¶‡•Å‡§ñ\", \"hota\": \"‡§π‡•ã‡§§‡§æ\", \"mala\": \"‡§Æ‡§≤‡§æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"mar_Deva\",\n",
        "        \"normalizer\": \"mr\"\n",
        "    },\n",
        "    \"bengali\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"ami\": \"‡¶Ü‡¶Æ‡¶ø\", \"tumi\": \"‡¶§‡ßÅ‡¶Æ‡¶ø\", \"tomar\": \"‡¶§‡ßã‡¶Æ‡¶æ‡¶∞\", \"ke\": \"‡¶ï‡ßá\",\n",
        "            \"sathe\": \"‡¶∏‡¶æ‡¶•‡ßá\", \"bhalo\": \"‡¶≠‡¶æ‡¶≤‡ßã\", \"jabo\": \"‡¶Ø‡¶æ‡¶¨‡ßã\", \"asche\": \"‡¶Ü‡¶∏‡ßá\",\n",
        "            \"korbo\": \"‡¶ï‡¶∞‡¶¨‡ßã\", \"amar\": \"‡¶Ü‡¶Æ‡¶æ‡¶∞\", \"kotha\": \"‡¶ï‡ßã‡¶•‡¶æ\", \"bari\": \"‡¶¨‡¶æ‡¶°‡¶º‡¶ø\",\n",
        "            \"achho\": \"‡¶Ü‡¶õ‡ßã\", \"ki\": \"‡¶ï‡¶ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.BENGALI,\n",
        "        \"lang_code_nllb\": \"ben_Beng\",\n",
        "        \"normalizer\": \"bn\"\n",
        "    },\n",
        "    \"malayalam\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"nee\": \"‡¥®‡µÄ\", \"lunch\": \"‡¥≤‡¥û‡µç‡¥ö‡µç\", \"eppozha\": \"‡¥é‡¥™‡µç‡¥™‡µã‡¥¥‡¥æ\", \"kazhicha\": \"‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö\",\n",
        "            \"innale\": \"‡¥á‡¥®‡µç‡¥®‡¥≤‡µÜ\", \"padam\": \"‡¥™‡¥ü‡¥Ç\", \"super\": \"‡¥∏‡µÇ‡¥™‡µç‡¥™‡µº\", \"family\": \"‡¥ï‡µÅ‡¥ü‡µÅ‡¥Ç‡¥¨‡¥Ç\",\n",
        "            \"meet\": \"‡¥Æ‡µÄ‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç\", \"poyi\": \"‡¥™‡µã‡¥Ø‡¥ø\", \"kananam\": \"‡¥ï‡¥æ‡¥£‡¥£‡¥Ç\", \"abhinayam\": \"‡¥Ö‡¥≠‡¥ø‡¥®‡¥Ø‡¥Ç\",\n",
        "            \"avanda\": \"‡¥Ö‡¥µ‡¥®‡µç‡¥±‡µÜ\", \"veettil\": \"‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ\", \"etthiyattu\": \"‡¥é‡¥§‡µç‡¥§‡¥ø‡¥Ø‡¥ø‡¥ü‡µç‡¥ü‡µç\",\n",
        "            \"call\": \"‡¥ï‡µã‡µæ\", \"namukku\": \"‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ\", \"today\": \"‡¥á‡¥®‡µç‡¥®‡µç\", \"signal\": \"‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ\",\n",
        "            \"valare\": \"‡¥µ‡¥≥‡¥∞‡µÜ\", \"weak\": \"‡¥µ‡µÄ‡¥ï‡µç\", \"ivide\": \"‡¥á‡¥µ‡¥ø‡¥ü‡µÜ\", \"aanu\": \"‡¥Ü‡¥£‡µç\",\n",
        "            \"try\": \"‡¥ü‡µç‡¥∞‡µà\", \"cheythu\": \"‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡µÅ\", \"nokku\": \"‡¥®‡µã‡¥ï‡µç‡¥ï‡µÅ\", \"easy\": \"‡¥á‡¥∏‡¥ø\",\n",
        "            \"car\": \"‡¥ï‡¥æ‡µº\", \"pothichu\": \"‡¥™‡µä‡¥§‡µç‡¥§‡¥ø‡¥ö‡µç‡¥ö‡µÅ\", \"office\": \"‡¥ì‡¥´‡µÄ‡¥∏‡µç\", \"late\": \"‡¥≤‡µá‡¥±‡µç‡¥±‡µç\",\n",
        "            \"review\": \"‡¥±‡¥ø‡¥µ‡µç‡¥Ø‡µÇ\", \"new\": \"‡¥®‡µç‡¥Ø‡µÇ\", \"think\": \"‡¥§‡¥ø‡¥ô‡µç‡¥ï‡µç\", \"kandittu\": \"‡¥ï‡¥£‡µç‡¥ü‡¥ø‡¥ü‡µç‡¥ü‡µç\",\n",
        "            \"weekend\": \"‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡¥®‡µç‡¥±‡µç\", \"okke\": \"‡¥í‡¥ï‡µç‡¥ï‡µÜ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.MALAYALAM,\n",
        "        \"lang_code_nllb\": \"mal_Mlym\",\n",
        "        \"normalizer\": \"ml\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Malayalam Preprocessing\n",
        "# =========================\n",
        "def preprocess_roman_malayalam(text):\n",
        "    \"\"\"Standardize romanized Malayalam input before transliteration/mapping.\"\"\"\n",
        "    text = text.lower().strip()\n",
        "    # Optionally add more replacements or normalization here.\n",
        "    return text\n",
        "\n",
        "# =========================\n",
        "# Core Functions (per language)\n",
        "# =========================\n",
        "def transliterate_roman_to_native(text: str, lang: str) -> str:\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    out_tokens = []\n",
        "    for tok in tokens:\n",
        "        low = tok.lower()\n",
        "        mapped = config[\"code_mix_dict\"].get(low)\n",
        "        if mapped:\n",
        "            out_tokens.append(mapped)\n",
        "        else:\n",
        "            if lang == \"malayalam\":\n",
        "                out_tokens.append(tok) # For Malayalam, don't transliterate if no mapping\n",
        "            else:\n",
        "                try:\n",
        "                    native = transliterate(tok, config[\"src_script\"], config[\"tgt_script\"])\n",
        "                    if re.search(r\"[A-Za-z]\", native):\n",
        "                        out_tokens.append(tok)\n",
        "                    else:\n",
        "                        out_tokens.append(native)\n",
        "                except Exception:\n",
        "                    out_tokens.append(tok)\n",
        "    return \" \".join(out_tokens).strip()\n",
        "\n",
        "def normalize_native_text(text: str, lang: str) -> str:\n",
        "    normalizer = indic_normalize.IndicNormalizerFactory().get_normalizer(LANG_CONFIG[lang][\"normalizer\"])\n",
        "    normalized = normalizer.normalize(text)\n",
        "    if lang == \"hindi\":\n",
        "        normalized = normalized.replace(\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\").replace(\"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó\", \"‡§¨‡•à‡§†‡§ï\")\n",
        "    elif lang == \"bengali\":\n",
        "        normalized = normalized.replace(\"‡¶≠‡¶æ‡¶≤\", \"‡¶≠‡¶æ‡¶≤‡ßã\")\n",
        "    elif lang == \"marathi\":\n",
        "        normalized = normalized.replace(\"‡§õ‡•ç‡§π‡§æ‡§®\", \"‡§õ‡§æ‡§®\").replace(\"\\u200c\", \"\").replace(\"\\u200b\", \"\")\n",
        "    return re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "def detect_code_mixed_words(text: str, lang: str):\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    return [tok for tok in tokens if tok.lower() in config[\"code_mix_dict\"] or re.match(r\"^[A-Za-z]+$\", tok)]\n",
        "\n",
        "# =========================\n",
        "# Translation (NLLB)\n",
        "# =========================\n",
        "def translate_nllb(text, src_lang, tgt_lang):\n",
        "    tokenizer_nllb.src_lang = src_lang\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_lang_id = tokenizer_nllb.convert_tokens_to_ids(tgt_lang)\n",
        "    generated = model_nllb.generate(**encoded, forced_bos_token_id=tgt_lang_id)\n",
        "    return tokenizer_nllb.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "# =========================\n",
        "# Combined Multilingual Pipeline\n",
        "# =========================\n",
        "def full_pipeline(input_text: str, input_lang: str, target_langs: list):\n",
        "    print(f\"\\nü™Ñ Step 0: Input Text: {input_text}\")\n",
        "    # Malayalam preprocessing\n",
        "    if input_lang == \"malayalam\":\n",
        "        input_text = preprocess_roman_malayalam(input_text)\n",
        "    # Step 1: Roman ‚Üí Native Script\n",
        "    native_text = transliterate_roman_to_native(input_text, input_lang)\n",
        "    print(f\"üà∂ Step 1: After Transliteration: {native_text}\")\n",
        "    # Step 2: Detect code-mixed words\n",
        "    code_mix = detect_code_mixed_words(input_text, input_lang)\n",
        "    print(f\"üîç Step 2: Detected code-mixed words: {code_mix}\")\n",
        "    # Step 3: Normalization\n",
        "    normalized_native = normalize_native_text(native_text, input_lang)\n",
        "    print(f\"ü™∂ Step 3: Normalized Text: {normalized_native}\")\n",
        "    # Step 4: Native ‚Üí English\n",
        "    english_text = translate_nllb(normalized_native, LANG_CONFIG[input_lang][\"lang_code_nllb\"], \"eng_Latn\")\n",
        "    print(f\"üá¨üáß Step 4: English Translation: {english_text}\")\n",
        "    # Step 5: English ‚Üí Target Languages\n",
        "    translations = {LANG_CONFIG[input_lang][\"lang_code_nllb\"]: normalized_native, \"eng_Latn\": english_text}\n",
        "    print(\"\\nüåç Step 5: Translations to Other Languages:\")\n",
        "    for lang in target_langs:\n",
        "        lang_code = LANG_CONFIG[lang][\"lang_code_nllb\"]\n",
        "        translated_text = translate_nllb(english_text, \"eng_Latn\", lang_code)\n",
        "        translations[lang_code] = translated_text\n",
        "        print(f\"{lang_code}: {translated_text}\")\n",
        "    print(\"\\n‚úÖ Multilingual translation pipeline complete!\")\n",
        "    return translations\n",
        "\n",
        "# =========================\n",
        "# Example Usage\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Malayalam example\n",
        "    INPUT_SENTENCE = \"ivide wifi signal valare weak aanu\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kMK6-BdD_dHx",
        "outputId": "a4d3e4b0-3627-4688-fd6e-43c6596ca7d3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: ivide wifi signal valare weak aanu\n",
            "üà∂ Step 1: After Transliteration: ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ wifi ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ ‡¥µ‡¥≥‡¥∞‡µÜ ‡¥µ‡µÄ‡¥ï‡µç ‡¥Ü‡¥£‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['ivide', 'wifi', 'signal', 'valare', 'weak', 'aanu']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ wifi ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ ‡¥µ‡¥≥‡¥∞‡µÜ ‡¥µ‡µÄ‡¥ï‡µç ‡¥Ü‡¥£‡µç\n",
            "üá¨üáß Step 4: English Translation: The wifi signal is very weak here.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§µ‡§æ‡§à‡§´‡§æ‡§à ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§π‡•à ‡§Ø‡§π‡§æ‡§Å.\n",
            "tam_Taml: ‡Æµ‡Øà‡ÆÉ‡Æ™‡Øà ‡Æö‡ÆÆ‡Æø‡Æï‡Øç‡Æû‡Øà ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Æ≤‡Æµ‡ØÄ‡Æ©‡ÆÆ‡Ææ‡Æï ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.\n",
            "tel_Telu: ‡∞µ‡±à‡∞´‡±à ‡∞∏‡∞ø‡∞ó‡±ç‡∞®‡∞≤‡±ç ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞¨‡∞≤‡∞π‡±Ä‡∞®‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§µ‡§æ‡§Ø‡§´‡§æ‡§Ø ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§ñ‡•Ç‡§™‡§ö ‡§ï‡§Æ‡§ï‡•Å‡§µ‡§§ ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤‡¶ü‡¶æ ‡¶ñ‡ßÅ‡¶¨ ‡¶¶‡ßÅ‡¶∞‡ßç‡¶¨‡¶≤‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Malayalam example\n",
        "    INPUT_SENTENCE = \"try cheythu nokku, easy aanu\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f4t30hh7AKtw",
        "outputId": "e79a7351-a5f8-4921-f4c5-ef6e5559017a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: try cheythu nokku, easy aanu\n",
            "üà∂ Step 1: After Transliteration: ‡¥ü‡µç‡¥∞‡µà ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡µÅ ‡¥®‡µã‡¥ï‡µç‡¥ï‡µÅ , ‡¥á‡¥∏‡¥ø ‡¥Ü‡¥£‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['try', 'cheythu', 'nokku', 'easy', 'aanu']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥ü‡µç‡¥∞‡µà ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡µÅ ‡¥®‡µã‡¥ï‡µç‡¥ï‡µÅ , ‡¥á‡¥∏‡¥ø ‡¥Ü‡¥£‡µç\n",
            "üá¨üáß Step 4: English Translation: Try it. It's easy.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•ã, ‡§Ø‡§π ‡§Ü‡§∏‡§æ‡§® ‡§π‡•à.\n",
            "tam_Taml: ‡ÆÖ‡Æ§‡Øà ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ‡ØÅ‡Æô‡Øç‡Æï‡Æ≥‡Øç. ‡ÆÖ‡Æ§‡ØÅ ‡Æé‡Æ≥‡Æø‡Æ§‡Ææ‡Æ©‡Æ§‡ØÅ.\n",
            "tel_Telu: ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø. ‡∞á‡∞¶‡∞ø ‡∞∏‡±Å‡∞≤‡∞≠‡∞Ç.\n",
            "mar_Deva: ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ. ‡§π‡•á ‡§∏‡•ã‡§™‡•á ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßã, ‡¶è‡¶ü‡¶æ ‡¶∏‡¶π‡¶ú‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Malayalam example\n",
        "    INPUT_SENTENCE = \"weekend-il family okke veettil aanu\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6I41MfekASOo",
        "outputId": "1a65b934-136b-477a-e398-216abfba2faf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: weekend-il family okke veettil aanu\n",
            "üà∂ Step 1: After Transliteration: ‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡¥®‡µç‡¥±‡µç - il ‡¥ï‡µÅ‡¥ü‡µÅ‡¥Ç‡¥¨‡¥Ç ‡¥í‡¥ï‡µç‡¥ï‡µÜ ‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ ‡¥Ü‡¥£‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['weekend', 'il', 'family', 'okke', 'veettil', 'aanu']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡¥®‡µç‡¥±‡µç - il ‡¥ï‡µÅ‡¥ü‡µÅ‡¥Ç‡¥¨‡¥Ç ‡¥í‡¥ï‡µç‡¥ï‡µÜ ‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ ‡¥Ü‡¥£‡µç\n",
            "üá¨üáß Step 4: English Translation: The whole family is home.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§™‡•Ç‡§∞‡§æ ‡§™‡§∞‡§ø‡§µ‡§æ‡§∞ ‡§ò‡§∞ ‡§™‡§∞ ‡§π‡•à‡•§\n",
            "tam_Taml: ‡ÆÆ‡ØÅ‡Æ¥‡ØÅ ‡Æï‡ØÅ‡Æü‡ØÅ‡ÆÆ‡Øç‡Æ™‡ÆÆ‡ØÅ‡ÆÆ‡Øç ‡Æµ‡ØÄ‡Æü‡Øç‡Æü‡Æø‡Æ≤‡Øç‡Æ§‡Ææ‡Æ©‡Øç ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Æ§‡ØÅ.\n",
            "tel_Telu: ‡∞ï‡±Å‡∞ü‡±Å‡∞Ç‡∞¨‡∞Ç ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞á‡∞Ç‡∞ü‡±ç‡∞≤‡±ã ‡∞â‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§∏‡§Ç‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•Å‡§ü‡•Å‡§Ç‡§¨ ‡§ò‡§∞‡•Ä ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶™‡ßÅ‡¶∞‡ßã ‡¶™‡¶∞‡¶ø‡¶¨‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶°‡¶º‡¶ø‡¶§‡ßá‡¶á ‡¶Ü‡¶õ‡ßá‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Malayalam example\n",
        "    INPUT_SENTENCE = \"nee lunch kazhicha?\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-FjIM-YTAoqv",
        "outputId": "3af111d4-65a2-496b-90c5-06aaf78e4e0f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: nee lunch kazhicha?\n",
            "üà∂ Step 1: After Transliteration: ‡¥®‡µÄ ‡¥≤‡¥û‡µç‡¥ö‡µç ‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö ?\n",
            "üîç Step 2: Detected code-mixed words: ['nee', 'lunch', 'kazhicha']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥®‡µÄ ‡¥≤‡¥û‡µç‡¥ö‡µç ‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö ?\n",
            "üá¨üáß Step 4: English Translation: Did you have lunch?\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§®‡•á ‡§¶‡•ã‡§™‡§π‡§∞ ‡§ï‡§æ ‡§≠‡•ã‡§ú‡§® ‡§ï‡§ø‡§Ø‡§æ?\n",
            "tam_Taml: ‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ§‡Æø‡ÆØ ‡Æâ‡Æ£‡Æµ‡ØÅ ‡Æö‡Ææ‡Æ™‡Øç‡Æ™‡Æø‡Æü‡Øç‡Æü‡ØÄ‡Æ∞‡Øç‡Æï‡Æ≥‡Ææ?\n",
            "tel_Telu: ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞≠‡±ã‡∞ú‡∞®‡∞Ç ‡∞ö‡±á‡∞∂‡∞æ‡∞∞‡±Å?\n",
            "mar_Deva: ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§≤‡§Ç‡§ö ‡§ï‡•á‡§≤‡§æ ‡§ï‡§æ?\n",
            "ben_Beng: ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ï‡¶ø ‡¶≤‡¶æ‡¶û‡ßç‡¶ö ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡¶≤‡ßá?\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Malayalam example\n",
        "    INPUT_SENTENCE = \"avanda veettil etthiyattu we will call you\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T7kVuoCmAxjh",
        "outputId": "2a573c1b-f265-4724-8e7f-bc3f5847e16c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: avanda veettil etthiyattu we will call you\n",
            "üà∂ Step 1: After Transliteration: ‡¥Ö‡¥µ‡¥®‡µç‡¥±‡µÜ ‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ ‡¥é‡¥§‡µç‡¥§‡¥ø‡¥Ø‡¥ø‡¥ü‡µç‡¥ü‡µç we will ‡¥ï‡µã‡µæ you\n",
            "üîç Step 2: Detected code-mixed words: ['avanda', 'veettil', 'etthiyattu', 'we', 'will', 'call', 'you']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥Ö‡¥µ‡¥®‡µç‡¥±‡µÜ ‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ ‡¥é‡¥§‡µç‡¥§‡¥ø‡¥Ø‡¥ø‡¥ü‡µç‡¥ü‡µç we will ‡¥ï‡µã‡µæ you\n",
            "üá¨üáß Step 4: English Translation: We'll call you when we get to his house.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§ú‡§¨ ‡§π‡§Æ ‡§â‡§∏‡§ï‡•á ‡§ò‡§∞ ‡§™‡§∞ ‡§™‡§π‡•Å‡§Å‡§ö‡•á‡§Ç‡§ó‡•á ‡§§‡•ã ‡§´‡•ã‡§® ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á‡•§\n",
            "tam_Taml: ‡Æ®‡Ææ‡ÆÆ‡Øç ‡ÆÖ‡Æµ‡Æ∞‡Æ§‡ØÅ ‡Æµ‡ØÄ‡Æü‡Øç‡Æü‡Æø‡Æ≤‡Øç ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Øã‡Æ§‡ØÅ ‡Æ®‡Ææ‡ÆÆ‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øà ‡ÆÖ‡Æ¥‡Øà‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç.\n",
            "tel_Telu: ‡∞Æ‡±á‡∞Æ‡±Å ‡∞Ö‡∞§‡∞®‡∞ø ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ï‡∞ø ‡∞µ‡∞ö‡±ç‡∞ö‡∞ø‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±á‡∞Æ‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ï‡∞æ‡∞≤‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§§‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§ò‡§∞‡•Ä ‡§™‡•ã‡§π‡•ã‡§ö‡§≤‡•ç‡§Ø‡§æ‡§µ‡§∞ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§´‡•ã‡§® ‡§ï‡§∞‡•Ç.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶Ø‡¶ñ‡¶® ‡¶§‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶°‡¶º‡¶ø‡¶§‡ßá ‡¶™‡ßå‡¶Å‡¶õ‡ßá ‡¶Ø‡¶æ‡¶¨ ‡¶§‡¶ñ‡¶® ‡¶§‡ßã‡¶Æ‡¶æ‡¶ï‡ßá ‡¶´‡ßã‡¶® ‡¶ï‡¶∞‡¶¨‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Malayalam example\n",
        "    INPUT_SENTENCE = \"today namukku meetam\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dVwrd3dxA2TG",
        "outputId": "3e9a5395-fb85-4c28-efc3-a259f71d7c5b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: today namukku meetam\n",
            "üà∂ Step 1: After Transliteration: ‡¥á‡¥®‡µç‡¥®‡µç ‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ meetam\n",
            "üîç Step 2: Detected code-mixed words: ['today', 'namukku', 'meetam']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥á‡¥®‡µç‡¥®‡µç ‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ meetam\n",
            "üá¨üáß Step 4: English Translation: Today we meetam\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Ü‡§ú ‡§π‡§Æ ‡§Æ‡§ø‡§≤‡§§‡•á ‡§π‡•à‡§Ç\n",
            "tam_Taml: ‡Æá‡Æ©‡Øç‡Æ±‡ØÅ ‡Æ®‡Ææ‡ÆÆ‡Øç ‡Æö‡Æ®‡Øç‡Æ§‡Æø‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øã‡ÆÆ‡Øç\n",
            "tel_Telu: ‡∞à ‡∞∞‡±ã‡∞ú‡±Å ‡∞Æ‡∞®‡∞Ç ‡∞ï‡∞≤‡±Å‡∞¶‡±ç‡∞¶‡∞æ‡∞Ç\n",
            "mar_Deva: ‡§Ü‡§ú ‡§Ü‡§™‡§£ ‡§≠‡•á‡§ü‡•Ç\n",
            "ben_Beng: ‡¶Ü‡¶ú‡¶ï‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡ßá‡¶ñ‡¶æ ‡¶ï‡¶∞‡¶¨‡ßã\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# =========================\n",
        "# Device Setup\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# Model Loading\n",
        "# =========================\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "# =========================\n",
        "# Settings (language parameters)\n",
        "# =========================\n",
        "LANG_CONFIG = {\n",
        "    \"hindi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡§ï‡§ï‡•ç‡§∑‡§æ\", \"meeting\": \"‡§¨‡•à‡§†‡§ï\", \"me\": \"‡§Æ‡•á‡§Ç\", \"after\": \"‡§¨‡§æ‡§¶\", \"ke\": \"‡§ï‡•á\", \"baad\": \"‡§¨‡§æ‡§¶\",\n",
        "            \"aana\": \"‡§Ü‡§®‡§æ\", \"hai\": \"‡§π‡•à\", \"mujhe\": \"‡§Æ‡•Å‡§ù‡•á\", \"please\": \"‡§ï‡•É‡§™‡§Ø‡§æ\", \"sir\": \"‡§∏‡§æ‡§π‡§¨\", \"madam\": \"‡§Æ‡•à‡§°‡§Æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"hin_Deva\",\n",
        "        \"normalizer\": \"hi\"\n",
        "    },\n",
        "    \"tamil\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"naan\": \"‡Æ®‡Ææ‡Æ©‡Øç\", \"nee\": \"‡Æ®‡ØÄ\", \"class\": \"‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç\", \"ku\": \"‡Æï‡Øç‡Æï‡ØÅ\", \"poganum\": \"‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"ponanum\": \"‡Æ™‡Øã‡Æµ‡Øá‡Æ©‡Øç\", \"varanum\": \"‡Æµ‡Æ∞‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"sollanum\": \"‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"pananum\": \"‡Æ™‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TAMIL,\n",
        "        \"lang_code_nllb\": \"tam_Taml\",\n",
        "        \"normalizer\": \"ta\"\n",
        "    },\n",
        "    \"telugu\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡∞§‡∞∞‡∞ó‡∞§‡∞ø\", \"vellali\": \"‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TELUGU,\n",
        "        \"lang_code_nllb\": \"tel_Telu\",\n",
        "        \"normalizer\": \"te\"\n",
        "    },\n",
        "    \"marathi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"tu\": \"‡§§‡•Ç\", \"tula\": \"‡§§‡•Å‡§≤‡§æ\", \"kasa\": \"‡§ï‡§∏‡§æ\", \"kasaa\": \"‡§ï‡§∏‡§æ\", \"aahe\": \"‡§Ü‡§π‡•á\", \"aahes\": \"‡§Ü‡§π‡•á‡§∏\", \"majha\": \"‡§Æ‡§æ‡§ù‡§æ\",\n",
        "            \"mazi\": \"‡§Æ‡§æ‡§ù‡•Ä\", \"maza\": \"‡§Æ‡§æ‡§ù‡§æ\", \"bandhu\": \"‡§≠‡§æ‡§ä\", \"mitra\": \"‡§Æ‡§ø‡§§‡•ç‡§∞\", \"aaj\": \"‡§Ü‡§ú\", \"udya\": \"‡§â‡§¶‡•ç‡§Ø‡§æ\",\n",
        "            \"school\": \"‡§∂‡§æ‡§≥‡§æ\", \"la\": \"‡§≤‡§æ\", \"nako\": \"‡§®‡§ï‡•ã\", \"karan\": \"‡§ï‡§æ‡§∞‡§£\", \"majha dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\",\n",
        "            \"maza dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\", \"bhet\": \"‡§≠‡•á‡§ü\", \"chhan\": \"‡§õ‡§æ‡§®\", \"movie\": \"‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü\",\n",
        "            \"pahila\": \"‡§™‡§æ‡§π‡§ø‡§≤‡§æ\", \"pahile\": \"‡§™‡§æ‡§π‡§ø‡§≤‡•á\", \"awesome\": \"‡§õ‡§æ‡§®\", \"mi\": \"‡§Æ‡•Ä\", \"jaato\": \"‡§ú‡§æ‡§§‡•ã\",\n",
        "            \"jatoy\": \"‡§ú‡§æ‡§§‡•ã\", \"nahi\": \"‡§®‡§æ‡§π‡•Ä\", \"aahe ka\": \"‡§Ü‡§π‡•á ‡§ï‡§æ\", \"dokyacha\": \"‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§ö‡§æ\",\n",
        "            \"dukh\": \"‡§¶‡•Å‡§ñ\", \"hota\": \"‡§π‡•ã‡§§‡§æ\", \"mala\": \"‡§Æ‡§≤‡§æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"mar_Deva\",\n",
        "        \"normalizer\": \"mr\"\n",
        "    },\n",
        "    \"bengali\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"ami\": \"‡¶Ü‡¶Æ‡¶ø\", \"tumi\": \"‡¶§‡ßÅ‡¶Æ‡¶ø\", \"tomar\": \"‡¶§‡ßã‡¶Æ‡¶æ‡¶∞\", \"ke\": \"‡¶ï‡ßá\",\n",
        "            \"sathe\": \"‡¶∏‡¶æ‡¶•‡ßá\", \"bhalo\": \"‡¶≠‡¶æ‡¶≤‡ßã\", \"jabo\": \"‡¶Ø‡¶æ‡¶¨‡ßã\", \"asche\": \"‡¶Ü‡¶∏‡ßá\",\n",
        "            \"korbo\": \"‡¶ï‡¶∞‡¶¨‡ßã\", \"amar\": \"‡¶Ü‡¶Æ‡¶æ‡¶∞\", \"kotha\": \"‡¶ï‡ßã‡¶•‡¶æ\", \"bari\": \"‡¶¨‡¶æ‡¶°‡¶º‡¶ø\",\n",
        "            \"achho\": \"‡¶Ü‡¶õ‡ßã\", \"ki\": \"‡¶ï‡¶ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.BENGALI,\n",
        "        \"lang_code_nllb\": \"ben_Beng\",\n",
        "        \"normalizer\": \"bn\"\n",
        "    },\n",
        "    \"malayalam\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"nee\": \"‡¥®‡µÄ\", \"lunch\": \"‡¥≤‡¥û‡µç‡¥ö‡µç\", \"eppozha\": \"‡¥é‡¥™‡µç‡¥™‡µã‡¥¥‡¥æ\", \"kazhicha\": \"‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö\",\n",
        "            \"innale\": \"‡¥á‡¥®‡µç‡¥®‡¥≤‡µÜ\", \"padam\": \"‡¥™‡¥ü‡¥Ç\", \"super\": \"‡¥∏‡µÇ‡¥™‡µç‡¥™‡µº\", \"family\": \"‡¥ï‡µÅ‡¥ü‡µÅ‡¥Ç‡¥¨‡¥Ç\",\n",
        "            \"meet\": \"‡¥Æ‡µÄ‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç\", \"poyi\": \"‡¥™‡µã‡¥Ø‡¥ø\", \"kananam\": \"‡¥ï‡¥æ‡¥£‡¥£‡¥Ç\", \"abhinayam\": \"‡¥Ö‡¥≠‡¥ø‡¥®‡¥Ø‡¥Ç\",\n",
        "            \"avanda\": \"‡¥Ö‡¥µ‡¥®‡µç‡¥±‡µÜ\", \"veettil\": \"‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ\", \"etthiyattu\": \"‡¥é‡¥§‡µç‡¥§‡¥ø‡¥Ø‡¥ø‡¥ü‡µç‡¥ü‡µç\",\n",
        "            \"call\": \"‡¥ï‡µã‡µæ\", \"namukku\": \"‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ\", \"today\": \"‡¥á‡¥®‡µç‡¥®‡µç\", \"signal\": \"‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ\",\n",
        "            \"valare\": \"‡¥µ‡¥≥‡¥∞‡µÜ\", \"weak\": \"‡¥µ‡µÄ‡¥ï‡µç\", \"ivide\": \"‡¥á‡¥µ‡¥ø‡¥ü‡µÜ\", \"aanu\": \"‡¥Ü‡¥£‡µç\",\n",
        "            \"try\": \"‡¥ü‡µç‡¥∞‡µà\", \"cheythu\": \"‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡µÅ\", \"nokku\": \"‡¥®‡µã‡¥ï‡µç‡¥ï‡µÅ\", \"easy\": \"‡¥á‡¥∏‡¥ø\",\n",
        "            \"car\": \"‡¥ï‡¥æ‡µº\", \"pothichu\": \"‡¥™‡µä‡¥§‡µç‡¥§‡¥ø‡¥ö‡µç‡¥ö‡µÅ\", \"office\": \"‡¥ì‡¥´‡µÄ‡¥∏‡µç\", \"late\": \"‡¥≤‡µá‡¥±‡µç‡¥±‡µç\",\n",
        "            \"review\": \"‡¥±‡¥ø‡¥µ‡µç‡¥Ø‡µÇ\", \"new\": \"‡¥®‡µç‡¥Ø‡µÇ\", \"think\": \"‡¥§‡¥ø‡¥ô‡µç‡¥ï‡µç\", \"kandittu\": \"‡¥ï‡¥£‡µç‡¥ü‡¥ø‡¥ü‡µç‡¥ü‡µç\",\n",
        "            \"weekend\": \"‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡¥®‡µç‡¥±‡µç\", \"okke\": \"‡¥í‡¥ï‡µç‡¥ï‡µÜ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.MALAYALAM,\n",
        "        \"lang_code_nllb\": \"mal_Mlym\",\n",
        "        \"normalizer\": \"ml\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def preprocess_roman_malayalam(text):\n",
        "    \"\"\"Standardize romanized Malayalam input before transliteration/mapping.\"\"\"\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "def transliterate_roman_to_native(text: str, lang: str) -> str:\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    out_tokens = []\n",
        "    for tok in tokens:\n",
        "        low = tok.lower()\n",
        "        mapped = config[\"code_mix_dict\"].get(low)\n",
        "        if mapped:\n",
        "            out_tokens.append(mapped)\n",
        "        elif lang == \"malayalam\":\n",
        "            out_tokens.append(tok)  # Only use dict mapping for Malayalam\n",
        "        else:\n",
        "            try:\n",
        "                native = transliterate(tok, config[\"src_script\"], config[\"tgt_script\"])\n",
        "                if re.search(r\"[A-Za-z]\", native):\n",
        "                    out_tokens.append(tok)\n",
        "                else:\n",
        "                    out_tokens.append(native)\n",
        "            except Exception:\n",
        "                out_tokens.append(tok)\n",
        "    return \" \".join(out_tokens).strip()\n",
        "\n",
        "def normalize_native_text(text: str, lang: str) -> str:\n",
        "    normalizer = indic_normalize.IndicNormalizerFactory().get_normalizer(LANG_CONFIG[lang][\"normalizer\"])\n",
        "    normalized = normalizer.normalize(text)\n",
        "    if lang == \"hindi\":\n",
        "        normalized = normalized.replace(\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\").replace(\"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó\", \"‡§¨‡•à‡§†‡§ï\")\n",
        "    elif lang == \"bengali\":\n",
        "        normalized = normalized.replace(\"‡¶≠‡¶æ‡¶≤\", \"‡¶≠‡¶æ‡¶≤‡ßã\")\n",
        "    elif lang == \"marathi\":\n",
        "        normalized = normalized.replace(\"‡§õ‡•ç‡§π‡§æ‡§®\", \"‡§õ‡§æ‡§®\").replace(\"\\u200c\", \"\").replace(\"\\u200b\", \"\")\n",
        "    return re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "def detect_code_mixed_words(text: str, lang: str):\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    return [tok for tok in tokens if tok.lower() in config[\"code_mix_dict\"] or re.match(r\"^[A-Za-z]+$\", tok)]\n",
        "\n",
        "def translate_nllb(text, src_lang, tgt_lang):\n",
        "    tokenizer_nllb.src_lang = src_lang\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_lang_id = tokenizer_nllb.convert_tokens_to_ids(tgt_lang)\n",
        "    generated = model_nllb.generate(**encoded, forced_bos_token_id=tgt_lang_id)\n",
        "    return tokenizer_nllb.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "def full_pipeline(input_text: str, input_lang: str, target_langs: list):\n",
        "    print(f\"\\nü™Ñ Step 0: Input Text: {input_text}\")\n",
        "    if input_lang == \"malayalam\":\n",
        "        input_text = preprocess_roman_malayalam(input_text)\n",
        "    native_text = transliterate_roman_to_native(input_text, input_lang)\n",
        "    print(f\"üà∂ Step 1: After Transliteration: {native_text}\")\n",
        "    code_mix = detect_code_mixed_words(input_text, input_lang)\n",
        "    print(f\"üîç Step 2: Detected code-mixed words: {code_mix}\")\n",
        "    normalized_native = normalize_native_text(native_text, input_lang)\n",
        "    print(f\"ü™∂ Step 3: Normalized Text: {normalized_native}\")\n",
        "    english_text = translate_nllb(normalized_native, LANG_CONFIG[input_lang][\"lang_code_nllb\"], \"eng_Latn\")\n",
        "    print(f\"üá¨üáß Step 4: English Translation: {english_text}\")\n",
        "    translations = {LANG_CONFIG[input_lang][\"lang_code_nllb\"]: normalized_native, \"eng_Latn\": english_text}\n",
        "    print(\"\\nüåç Step 5: Translations to Other Languages:\")\n",
        "    for lang in target_langs:\n",
        "        lang_code = LANG_CONFIG[lang][\"lang_code_nllb\"]\n",
        "        translated_text = translate_nllb(english_text, \"eng_Latn\", lang_code)\n",
        "        translations[lang_code] = translated_text\n",
        "        print(f\"{lang_code}: {translated_text}\")\n",
        "    print(\"\\n‚úÖ Multilingual translation pipeline complete!\")\n",
        "    return translations\n",
        "\n",
        "# =========================\n",
        "# Example Usage\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Malayalam example\n",
        "    INPUT_SENTENCE = \"ivide wifi signal valare weak aanu\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)\n",
        "\n",
        "    # Hindi example\n",
        "    INPUT_SENTENCE2 = \"mujhe class ke baad meeting me aana hai\"\n",
        "    INPUT_LANG2 = \"hindi\"\n",
        "    TARGET_LANGUAGES2 = [\"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results2 = full_pipeline(INPUT_SENTENCE2, INPUT_LANG2, TARGET_LANGUAGES2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b34Goq9sBwRC",
        "outputId": "f45ccab4-e021-4ce6-c6b6-a0683ccdc318"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: ivide wifi signal valare weak aanu\n",
            "üà∂ Step 1: After Transliteration: ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ wifi ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ ‡¥µ‡¥≥‡¥∞‡µÜ ‡¥µ‡µÄ‡¥ï‡µç ‡¥Ü‡¥£‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['ivide', 'wifi', 'signal', 'valare', 'weak', 'aanu']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ wifi ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ ‡¥µ‡¥≥‡¥∞‡µÜ ‡¥µ‡µÄ‡¥ï‡µç ‡¥Ü‡¥£‡µç\n",
            "üá¨üáß Step 4: English Translation: The wifi signal is very weak here.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§µ‡§æ‡§à‡§´‡§æ‡§à ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§π‡•à ‡§Ø‡§π‡§æ‡§Å.\n",
            "tam_Taml: ‡Æµ‡Øà‡ÆÉ‡Æ™‡Øà ‡Æö‡ÆÆ‡Æø‡Æï‡Øç‡Æû‡Øà ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Æ≤‡Æµ‡ØÄ‡Æ©‡ÆÆ‡Ææ‡Æï ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.\n",
            "tel_Telu: ‡∞µ‡±à‡∞´‡±à ‡∞∏‡∞ø‡∞ó‡±ç‡∞®‡∞≤‡±ç ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞¨‡∞≤‡∞π‡±Ä‡∞®‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§µ‡§æ‡§Ø‡§´‡§æ‡§Ø ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§ñ‡•Ç‡§™‡§ö ‡§ï‡§Æ‡§ï‡•Å‡§µ‡§§ ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤‡¶ü‡¶æ ‡¶ñ‡ßÅ‡¶¨ ‡¶¶‡ßÅ‡¶∞‡ßç‡¶¨‡¶≤‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "ü™Ñ Step 0: Input Text: mujhe class ke baad meeting me aana hai\n",
            "üà∂ Step 1: After Transliteration: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§¨‡•à‡§†‡§ï ‡§Æ‡•á‡§Ç ‡§Ü‡§®‡§æ ‡§π‡•à\n",
            "üîç Step 2: Detected code-mixed words: ['mujhe', 'class', 'ke', 'baad', 'meeting', 'me', 'aana', 'hai']\n",
            "ü™∂ Step 3: Normalized Text: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§¨‡•à‡§†‡§ï ‡§Æ‡•á‡§Ç ‡§Ü‡§®‡§æ ‡§π‡•à\n",
            "üá¨üáß Step 4: English Translation: I have to come to the meeting after class.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æµ‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ ‡Æ™‡Æø‡Æ±‡Æï‡ØÅ ‡Æï‡ØÇ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æµ‡Æ∞ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç.\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞§‡∞∞‡∞ó‡∞§‡∞ø ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞µ‡±á‡∞∂‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∞‡∞æ‡∞µ‡∞æ‡∞≤‡∞ø.\n",
            "mar_Deva: ‡§Æ‡§≤‡§æ ‡§µ‡§∞‡•ç‡§ó‡§æ‡§®‡§Ç‡§§‡§∞ ‡§¨‡•à‡§†‡§ï‡•Ä‡§≤‡§æ ‡§Ø‡•á‡§£‡§Ç ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶∂‡ßá‡¶∑‡ßá ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá ‡¶Ü‡¶∏‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"üß† MULTILINGUAL TRANSLATION TESTS ‚Äî ROUND 2\")\n",
        "    print(\"===========================================\\n\")\n",
        "\n",
        "    # 1Ô∏è‚É£ Hindi ‚Üí Other Indian languages\n",
        "    print(\"üáÆüá≥ Hindi ‚ûú Tamil / Telugu / Marathi / Bengali / Malayalam\\n\")\n",
        "    INPUT_SENTENCE1 = \"aaj mujhe ghar jaldi pahunchna hai\"  # I need to reach home early today\n",
        "    INPUT_LANG1 = \"hindi\"\n",
        "    TARGET_LANGUAGES1 = [\"tamil\", \"telugu\", \"marathi\", \"bengali\", \"malayalam\"]\n",
        "    results1 = full_pipeline(INPUT_SENTENCE1, INPUT_LANG1, TARGET_LANGUAGES1)\n",
        "\n",
        "    # 2Ô∏è‚É£ Tamil ‚Üí Other Indian languages\n",
        "    print(\"\\nüáÆüá≥ Tamil ‚ûú Hindi / Telugu / Marathi / Bengali / Malayalam\\n\")\n",
        "    INPUT_SENTENCE2 = \"naan inikku market ku poren\"  # I am going to the market today\n",
        "    INPUT_LANG2 = \"tamil\"\n",
        "    TARGET_LANGUAGES2 = [\"hindi\", \"telugu\", \"marathi\", \"bengali\", \"malayalam\"]\n",
        "    results2 = full_pipeline(INPUT_SENTENCE2, INPUT_LANG2, TARGET_LANGUAGES2)\n",
        "\n",
        "    # 3Ô∏è‚É£ Telugu ‚Üí Other Indian languages\n",
        "    print(\"\\nüáÆüá≥ Telugu ‚ûú Hindi / Tamil / Marathi / Bengali / Malayalam\\n\")\n",
        "    INPUT_SENTENCE3 = \"nenu eeroju pani ki vellanu\"  # I went to work today\n",
        "    INPUT_LANG3 = \"telugu\"\n",
        "    TARGET_LANGUAGES3 = [\"hindi\", \"tamil\", \"marathi\", \"bengali\", \"malayalam\"]\n",
        "    results3 = full_pipeline(INPUT_SENTENCE3, INPUT_LANG3, TARGET_LANGUAGES3)\n",
        "\n",
        "    # 4Ô∏è‚É£ Marathi ‚Üí Other Indian languages\n",
        "    print(\"\\nüáÆüá≥ Marathi ‚ûú Hindi / Tamil / Telugu / Bengali / Malayalam\\n\")\n",
        "    INPUT_SENTENCE4 = \"majha mobile charge nahi aahe\"  # My phone is not charged\n",
        "    INPUT_LANG4 = \"marathi\"\n",
        "    TARGET_LANGUAGES4 = [\"hindi\", \"tamil\", \"telugu\", \"bengali\", \"malayalam\"]\n",
        "    results4 = full_pipeline(INPUT_SENTENCE4, INPUT_LANG4, TARGET_LANGUAGES4)\n",
        "\n",
        "    # 5Ô∏è‚É£ Bengali ‚Üí Other Indian languages\n",
        "    print(\"\\nüáÆüá≥ Bengali ‚ûú Hindi / Tamil / Telugu / Marathi / Malayalam\\n\")\n",
        "    INPUT_SENTENCE5 = \"ami aj school e jabo na\"  # I will not go to school today\n",
        "    INPUT_LANG5 = \"bengali\"\n",
        "    TARGET_LANGUAGES5 = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"malayalam\"]\n",
        "    results5 = full_pipeline(INPUT_SENTENCE5, INPUT_LANG5, TARGET_LANGUAGES5)\n",
        "\n",
        "    # 6Ô∏è‚É£ Malayalam ‚Üí Other Indian languages\n",
        "    print(\"\\nüáÆüá≥ Malayalam ‚ûú Hindi / Tamil / Telugu / Marathi / Bengali\\n\")\n",
        "    INPUT_SENTENCE6 = \"ente friend innu varilla\"  # My friend is not coming today\n",
        "    INPUT_LANG6 = \"malayalam\"\n",
        "    TARGET_LANGUAGES6 = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results6 = full_pipeline(INPUT_SENTENCE6, INPUT_LANG6, TARGET_LANGUAGES6)\n",
        "\n",
        "    print(\"\\n‚úÖ All translation tests completed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Rg2id6ouDuWC",
        "outputId": "c4a27d53-276a-44f3-bc20-53ecf63503b1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† MULTILINGUAL TRANSLATION TESTS ‚Äî ROUND 2\n",
            "===========================================\n",
            "\n",
            "üáÆüá≥ Hindi ‚ûú Tamil / Telugu / Marathi / Bengali / Malayalam\n",
            "\n",
            "\n",
            "ü™Ñ Step 0: Input Text: aaj mujhe ghar jaldi pahunchna hai\n",
            "üà∂ Step 1: After Transliteration: ‡§Ü‡§ú‡•ç ‡§Æ‡•Å‡§ù‡•á ‡§ò‡§∞‡•ç ‡§ú‡§≤‡•ç‡§¶‡§ø ‡§™‡§π‡•Å‡§®‡•ç‡§ö‡•ç‡§® ‡§π‡•à\n",
            "üîç Step 2: Detected code-mixed words: ['aaj', 'mujhe', 'ghar', 'jaldi', 'pahunchna', 'hai']\n",
            "ü™∂ Step 3: Normalized Text: ‡§Ü‡§ú‡•ç ‡§Æ‡•Å‡§ù‡•á ‡§ò‡§∞‡•ç ‡§ú‡§≤‡•ç‡§¶‡§ø ‡§™‡§π‡•Å‡§®‡•ç‡§ö‡•ç‡§® ‡§π‡•à\n",
            "üá¨üáß Step 4: English Translation: I have to get home soon.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æµ‡Æø‡Æ∞‡Øà‡Æµ‡Æø‡Æ≤‡Øç ‡Æµ‡ØÄ‡Æü‡Øç‡Æü‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æö‡ØÜ‡Æ≤‡Øç‡Æ≤ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç.\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞§‡±ç‡∞µ‡∞∞‡∞≤‡±ã ‡∞á‡∞Ç‡∞ü‡∞ø‡∞ï‡∞ø ‡∞µ‡±Ü‡∞≥‡±ç‡∞≥‡∞æ‡∞≤‡∞ø.\n",
            "mar_Deva: ‡§Æ‡§≤‡§æ ‡§≤‡§µ‡§ï‡§∞‡§ö ‡§ò‡§∞‡•Ä ‡§ú‡§æ‡§Ø‡§ö‡§Ç ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶ø ‡¶§‡¶æ‡¶°‡¶º‡¶æ‡¶§‡¶æ‡¶°‡¶º‡¶ø ‡¶¨‡¶æ‡¶°‡¶º‡¶ø ‡¶Ø‡ßá‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§\n",
            "mal_Mlym: ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥â‡¥ü‡¥®‡µÜ ‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡¥≤‡µá‡¥ï‡µç‡¥ï‡µÅ ‡¥™‡µã‡¥ï‡¥£‡¥Ç.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "üáÆüá≥ Tamil ‚ûú Hindi / Telugu / Marathi / Bengali / Malayalam\n",
            "\n",
            "\n",
            "ü™Ñ Step 0: Input Text: naan inikku market ku poren\n",
            "üà∂ Step 1: After Transliteration: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æá‡Æ®‡Æø‡Æï‡Øç‡Æï‡ØÅ ‡ÆÆ‡Æ∞‡Øç‡Æï‡Øá‡Æ§‡Øç ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æ∞‡Øá‡Æ®‡Øç\n",
            "üîç Step 2: Detected code-mixed words: ['naan', 'inikku', 'market', 'ku', 'poren']\n",
            "ü™∂ Step 3: Normalized Text: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æá‡Æ®‡Æø‡Æï‡Øç‡Æï‡ØÅ ‡ÆÆ‡Æ∞‡Øç‡Æï‡Øá‡Æ§‡Øç ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æ∞‡Øá‡Æ®‡Øç\n",
            "üá¨üáß Step 4: English Translation: I went to Iniki Margeth\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç ‡§á‡§®‡•Ä‡§ï‡•Ä ‡§Æ‡§æ‡§∞‡•ç‡§ó‡•á‡§• ‡§ï‡•á ‡§™‡§æ‡§∏ ‡§ó‡§Ø‡§æ\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞á‡∞®‡∞ø‡∞ï‡±Ä ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ó‡±Ü‡∞§‡±ç‡∞ï‡±Å ‡∞µ‡±Ü‡∞≥‡±ç‡∞≥‡∞æ‡∞®‡±Å\n",
            "mar_Deva: ‡§Æ‡•Ä ‡§á‡§®‡•Ä‡§ï‡•Ä ‡§Æ‡§æ‡§∞‡•ç‡§ó‡•á‡§•‡§≤‡§æ ‡§ó‡•á‡§≤‡•ã.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶ø ‡¶á‡¶®‡¶ø‡¶ï‡¶ø ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶•‡ßá‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶ó‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ\n",
            "mal_Mlym: ‡¥û‡¥æ‡µª ‡¥á‡¥®‡¥ø‡¥ï‡µç‡¥ï‡¥ø ‡¥Æ‡¥æ‡µº‡¥ó‡µÜ‡¥§‡µç‡¥§‡µç ‡¥™‡µã‡¥Ø‡¥ø\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "üáÆüá≥ Telugu ‚ûú Hindi / Tamil / Marathi / Bengali / Malayalam\n",
            "\n",
            "\n",
            "ü™Ñ Step 0: Input Text: nenu eeroju pani ki vellanu\n",
            "üà∂ Step 1: After Transliteration: ‡∞®‡±á‡∞®‡±Å ‡∞à‡∞∞‡±ã‡∞ú‡±Å ‡∞™‡∞®‡∞ø ‡∞ï‡∞ø ‡∞µ‡±á‡∞≤‡±ç‡∞≤‡∞®‡±Å\n",
            "üîç Step 2: Detected code-mixed words: ['nenu', 'eeroju', 'pani', 'ki', 'vellanu']\n",
            "ü™∂ Step 3: Normalized Text: ‡∞®‡±á‡∞®‡±Å ‡∞à‡∞∞‡±ã‡∞ú‡±Å ‡∞™‡∞®‡∞ø ‡∞ï‡∞ø ‡∞µ‡±á‡∞≤‡±ç‡∞≤‡∞®‡±Å\n",
            "üá¨üáß Step 4: English Translation: I'm going to work today.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç ‡§Ü‡§ú ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡•á ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å.\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æá‡Æ©‡Øç‡Æ±‡ØÅ ‡Æµ‡Øá‡Æ≤‡Øà‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç.\n",
            "mar_Deva: ‡§Æ‡•Ä ‡§Ü‡§ú ‡§ï‡§æ‡§Æ‡§æ‡§µ‡§∞ ‡§ú‡§æ‡§§‡•ã.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶ú ‡¶ï‡¶æ‡¶ú‡ßá ‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡¶ø‡•§\n",
            "mal_Mlym: ‡¥á‡¥®‡µç‡¥®‡µç ‡¥û‡¥æ‡µª ‡¥ú‡µã‡¥≤‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥™‡µã‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "üáÆüá≥ Marathi ‚ûú Hindi / Tamil / Telugu / Bengali / Malayalam\n",
            "\n",
            "\n",
            "ü™Ñ Step 0: Input Text: majha mobile charge nahi aahe\n",
            "üà∂ Step 1: After Transliteration: ‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡•ã‡§¨‡§ø‡§≤‡•á ‡§ö‡§∞‡•ç‡§ó‡•á ‡§®‡§æ‡§π‡•Ä ‡§Ü‡§π‡•á\n",
            "üîç Step 2: Detected code-mixed words: ['majha', 'mobile', 'charge', 'nahi', 'aahe']\n",
            "ü™∂ Step 3: Normalized Text: ‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡•ã‡§¨‡§ø‡§≤‡•á ‡§ö‡§∞‡•ç‡§ó‡•á ‡§®‡§æ‡§π‡•Ä ‡§Ü‡§π‡•á\n",
            "üá¨üáß Step 4: English Translation: My phone is not cracked.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•á‡§∞‡§æ ‡§´‡•ã‡§® ‡§´‡§ü‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à.\n",
            "tam_Taml: ‡Æé‡Æ©‡Øç ‡Æ§‡Øä‡Æ≤‡Øà‡Æ™‡Øá‡Æö‡Æø ‡Æâ‡Æü‡Øà‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Æµ‡Æø‡Æ≤‡Øç‡Æ≤‡Øà.\n",
            "tel_Telu: ‡∞®‡∞æ ‡∞´‡±ã‡∞®‡±ç ‡∞™‡∞ó‡±Å‡∞≥‡±ç‡∞≤‡±Å ‡∞≤‡±á‡∞¶‡±Å.\n",
            "ben_Beng: ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶´‡ßã‡¶®‡¶ü‡¶æ ‡¶´‡¶æ‡¶ü‡¶≤ ‡¶π‡¶Ø‡¶º‡¶®‡¶ø‡•§\n",
            "mal_Mlym: ‡¥é‡¥®‡µç‡¥±‡µÜ ‡¥´‡µã‡µ∫ ‡¥§‡¥ï‡µº‡¥®‡µç‡¥®‡¥ø‡¥ü‡µç‡¥ü‡¥ø‡¥≤‡µç‡¥≤.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "üáÆüá≥ Bengali ‚ûú Hindi / Tamil / Telugu / Marathi / Malayalam\n",
            "\n",
            "\n",
            "ü™Ñ Step 0: Input Text: ami aj school e jabo na\n",
            "üà∂ Step 1: After Transliteration: ‡¶Ü‡¶Æ‡¶ø ‡¶Ö‡¶ú‡ßç ‡¶∏‡ßç‡¶ö‡ßÇ‡¶≤‡ßç ‡¶è ‡¶Ø‡¶æ‡¶¨‡ßã ‡¶®\n",
            "üîç Step 2: Detected code-mixed words: ['ami', 'aj', 'school', 'e', 'jabo', 'na']\n",
            "ü™∂ Step 3: Normalized Text: ‡¶Ü‡¶Æ‡¶ø ‡¶Ö‡¶ú‡ßç ‡¶∏‡ßç‡¶ö‡ßÇ‡¶≤‡ßç ‡¶è ‡¶Ø‡¶æ‡¶¨‡ßã ‡¶®\n",
            "üá¨üáß Step 4: English Translation: I'm not going to Azshul.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§Æ‡•à‡§Ç ‡§Ö‡§ú‡§º‡§∂‡•Å‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å.\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡ÆÖ‡Æ∏‡Øç‡Æ∑‡ØÅ‡Æ≤‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æï‡ÆÆ‡Ææ‡Æü‡Øç‡Æü‡Øá‡Æ©‡Øç.\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞Ö‡∞ú‡±ç‡∞∑‡±Å‡∞≤‡±ç ‡∞µ‡±Ü‡∞≥‡±ç‡∞≥‡∞°‡∞Ç ‡∞≤‡±á‡∞¶‡±Å.\n",
            "mar_Deva: ‡§Æ‡•Ä ‡§Ö‡§ù‡•Å‡§≤‡§≤‡§æ ‡§ú‡§æ‡§£‡§æ‡§∞ ‡§®‡§æ‡§π‡•Ä.\n",
            "mal_Mlym: ‡¥û‡¥æ‡µª ‡¥Ö‡¥∑‡µç‡¥π‡µÅ‡¥≤‡µç ‡¥™‡µã‡¥ï‡µÅ‡¥®‡µç‡¥®‡¥ø‡¥≤‡µç‡¥≤.\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "üáÆüá≥ Malayalam ‚ûú Hindi / Tamil / Telugu / Marathi / Bengali\n",
            "\n",
            "\n",
            "ü™Ñ Step 0: Input Text: ente friend innu varilla\n",
            "üà∂ Step 1: After Transliteration: ente friend innu varilla\n",
            "üîç Step 2: Detected code-mixed words: ['ente', 'friend', 'innu', 'varilla']\n",
            "ü™∂ Step 3: Normalized Text: ente friend innu varilla\n",
            "üá¨üáß Step 4: English Translation: The friend of the innu varilla\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: Innu varilla ‡§ï‡•á ‡§¶‡•ã‡§∏‡•ç‡§§\n",
            "tam_Taml: Innu varilla ‡Æá‡Æ©‡Øç ‡Æ®‡Æ£‡Øç‡Æ™‡Æ∞‡Øç\n",
            "tel_Telu: Innu varilla ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞ø‡∞§‡±Å‡∞°‡±Å\n",
            "mar_Deva: ‡§á‡§®‡•Å ‡§µ‡•à‡§∞‡§ø‡§≤‡§æ‡§ö‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\n",
            "ben_Beng: ‡¶á‡¶®‡ßÅ ‡¶≠‡ßá‡¶∞‡¶ø‡¶≤‡¶æ‡¶∞ ‡¶¨‡¶®‡ßç‡¶ß‡ßÅ\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "‚úÖ All translation tests completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# =========================\n",
        "# Device Setup\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# Model Loading\n",
        "# =========================\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "# =========================\n",
        "# Language Configurations\n",
        "# =========================\n",
        "LANG_CONFIG = {\n",
        "    \"hindi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡§ï‡§ï‡•ç‡§∑‡§æ\", \"meeting\": \"‡§¨‡•à‡§†‡§ï\", \"me\": \"‡§Æ‡•á‡§Ç\", \"after\": \"‡§¨‡§æ‡§¶\", \"ke\": \"‡§ï‡•á\", \"baad\": \"‡§¨‡§æ‡§¶\",\n",
        "            \"aana\": \"‡§Ü‡§®‡§æ\", \"hai\": \"‡§π‡•à\", \"mujhe\": \"‡§Æ‡•Å‡§ù‡•á\", \"please\": \"‡§ï‡•É‡§™‡§Ø‡§æ\", \"sir\": \"‡§∏‡§æ‡§π‡§¨\", \"madam\": \"‡§Æ‡•à‡§°‡§Æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"hin_Deva\",\n",
        "        \"normalizer\": \"hi\"\n",
        "    },\n",
        "    \"tamil\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"naan\": \"‡Æ®‡Ææ‡Æ©‡Øç\", \"nee\": \"‡Æ®‡ØÄ\", \"class\": \"‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç\", \"ku\": \"‡Æï‡Øç‡Æï‡ØÅ\", \"poganum\": \"‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"ponanum\": \"‡Æ™‡Øã‡Æµ‡Øá‡Æ©‡Øç\", \"varanum\": \"‡Æµ‡Æ∞‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"sollanum\": \"‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"pananum\": \"‡Æ™‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TAMIL,\n",
        "        \"lang_code_nllb\": \"tam_Taml\",\n",
        "        \"normalizer\": \"ta\"\n",
        "    },\n",
        "    \"telugu\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡∞§‡∞∞‡∞ó‡∞§‡∞ø\", \"vellali\": \"‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TELUGU,\n",
        "        \"lang_code_nllb\": \"tel_Telu\",\n",
        "        \"normalizer\": \"te\"\n",
        "    },\n",
        "    \"marathi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"tu\": \"‡§§‡•Ç\", \"tula\": \"‡§§‡•Å‡§≤‡§æ\", \"kasa\": \"‡§ï‡§∏‡§æ\", \"kasaa\": \"‡§ï‡§∏‡§æ\", \"aahe\": \"‡§Ü‡§π‡•á\", \"aahes\": \"‡§Ü‡§π‡•á‡§∏\", \"majha\": \"‡§Æ‡§æ‡§ù‡§æ\",\n",
        "            \"mazi\": \"‡§Æ‡§æ‡§ù‡•Ä\", \"maza\": \"‡§Æ‡§æ‡§ù‡§æ\", \"bandhu\": \"‡§≠‡§æ‡§ä\", \"mitra\": \"‡§Æ‡§ø‡§§‡•ç‡§∞\", \"aaj\": \"‡§Ü‡§ú\", \"udya\": \"‡§â‡§¶‡•ç‡§Ø‡§æ\",\n",
        "            \"school\": \"‡§∂‡§æ‡§≥‡§æ\", \"la\": \"‡§≤‡§æ\", \"nako\": \"‡§®‡§ï‡•ã\", \"karan\": \"‡§ï‡§æ‡§∞‡§£\", \"majha dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\",\n",
        "            \"maza dost\": \"‡§Æ‡§æ‡§ù‡§æ ‡§Æ‡§ø‡§§‡•ç‡§∞\", \"bhet\": \"‡§≠‡•á‡§ü\", \"chhan\": \"‡§õ‡§æ‡§®\", \"movie\": \"‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü\",\n",
        "            \"pahila\": \"‡§™‡§æ‡§π‡§ø‡§≤‡§æ\", \"pahile\": \"‡§™‡§æ‡§π‡§ø‡§≤‡•á\", \"awesome\": \"‡§õ‡§æ‡§®\", \"mi\": \"‡§Æ‡•Ä\", \"jaato\": \"‡§ú‡§æ‡§§‡•ã\",\n",
        "            \"jatoy\": \"‡§ú‡§æ‡§§‡•ã\", \"nahi\": \"‡§®‡§æ‡§π‡•Ä\", \"aahe ka\": \"‡§Ü‡§π‡•á ‡§ï‡§æ\", \"dokyacha\": \"‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§ö‡§æ\",\n",
        "            \"dukh\": \"‡§¶‡•Å‡§ñ\", \"hota\": \"‡§π‡•ã‡§§‡§æ\", \"mala\": \"‡§Æ‡§≤‡§æ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"mar_Deva\",\n",
        "        \"normalizer\": \"mr\"\n",
        "    },\n",
        "    \"bengali\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"ami\": \"‡¶Ü‡¶Æ‡¶ø\", \"tumi\": \"‡¶§‡ßÅ‡¶Æ‡¶ø\", \"tomar\": \"‡¶§‡ßã‡¶Æ‡¶æ‡¶∞\", \"ke\": \"‡¶ï‡ßá\",\n",
        "            \"sathe\": \"‡¶∏‡¶æ‡¶•‡ßá\", \"bhalo\": \"‡¶≠‡¶æ‡¶≤‡ßã\", \"jabo\": \"‡¶Ø‡¶æ‡¶¨‡ßã\", \"asche\": \"‡¶Ü‡¶∏‡ßá\",\n",
        "            \"korbo\": \"‡¶ï‡¶∞‡¶¨‡ßã\", \"amar\": \"‡¶Ü‡¶Æ‡¶æ‡¶∞\", \"kotha\": \"‡¶ï‡ßã‡¶•‡¶æ\", \"bari\": \"‡¶¨‡¶æ‡¶°‡¶º‡¶ø\",\n",
        "            \"achho\": \"‡¶Ü‡¶õ‡ßã\", \"ki\": \"‡¶ï‡¶ø\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.BENGALI,\n",
        "        \"lang_code_nllb\": \"ben_Beng\",\n",
        "        \"normalizer\": \"bn\"\n",
        "    },\n",
        "    \"malayalam\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"nee\": \"‡¥®‡µÄ\", \"lunch\": \"‡¥≤‡¥û‡µç‡¥ö‡µç\", \"eppozha\": \"‡¥é‡¥™‡µç‡¥™‡µã‡¥¥‡¥æ\", \"kazhicha\": \"‡¥ï‡¥¥‡¥ø‡¥ö‡µç‡¥ö\",\n",
        "            \"innale\": \"‡¥á‡¥®‡µç‡¥®‡¥≤‡µÜ\", \"padam\": \"‡¥™‡¥ü‡¥Ç\", \"super\": \"‡¥∏‡µÇ‡¥™‡µç‡¥™‡µº\", \"family\": \"‡¥ï‡µÅ‡¥ü‡µÅ‡¥Ç‡¥¨‡¥Ç\",\n",
        "            \"meet\": \"‡¥Æ‡µÄ‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡µç\", \"poyi\": \"‡¥™‡µã‡¥Ø‡¥ø\", \"kananam\": \"‡¥ï‡¥æ‡¥£‡¥£‡¥Ç\", \"abhinayam\": \"‡¥Ö‡¥≠‡¥ø‡¥®‡¥Ø‡¥Ç\",\n",
        "            \"avanda\": \"‡¥Ö‡¥µ‡¥®‡µç‡¥±‡µÜ\", \"veettil\": \"‡¥µ‡µÄ‡¥ü‡µç‡¥ü‡¥ø‡µΩ\", \"etthiyattu\": \"‡¥é‡¥§‡µç‡¥§‡¥ø‡¥Ø‡¥ø‡¥ü‡µç‡¥ü‡µç\",\n",
        "            \"call\": \"‡¥ï‡µã‡µæ\", \"namukku\": \"‡¥®‡¥Æ‡µÅ‡¥ï‡µç‡¥ï‡µÅ\", \"today\": \"‡¥á‡¥®‡µç‡¥®‡µç\", \"signal\": \"‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ\",\n",
        "            \"valare\": \"‡¥µ‡¥≥‡¥∞‡µÜ\", \"weak\": \"‡¥µ‡µÄ‡¥ï‡µç\", \"ivide\": \"‡¥á‡¥µ‡¥ø‡¥ü‡µÜ\", \"aanu\": \"‡¥Ü‡¥£‡µç\",\n",
        "            \"try\": \"‡¥ü‡µç‡¥∞‡µà\", \"cheythu\": \"‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡µÅ\", \"nokku\": \"‡¥®‡µã‡¥ï‡µç‡¥ï‡µÅ\", \"easy\": \"‡¥á‡¥∏‡¥ø\",\n",
        "            \"car\": \"‡¥ï‡¥æ‡µº\", \"pothichu\": \"‡¥™‡µä‡¥§‡µç‡¥§‡¥ø‡¥ö‡µç‡¥ö‡µÅ\", \"office\": \"‡¥ì‡¥´‡µÄ‡¥∏‡µç\", \"late\": \"‡¥≤‡µá‡¥±‡µç‡¥±‡µç\",\n",
        "            \"review\": \"‡¥±‡¥ø‡¥µ‡µç‡¥Ø‡µÇ\", \"new\": \"‡¥®‡µç‡¥Ø‡µÇ\", \"think\": \"‡¥§‡¥ø‡¥ô‡µç‡¥ô‡µç\", \"kandittu\": \"‡¥ï‡¥£‡µç‡¥ü‡¥ø‡¥ü‡µç‡¥ü‡µç\",\n",
        "            \"weekend\": \"‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡¥®‡µç‡¥±‡µç\", \"okke\": \"‡¥í‡¥ï‡µç‡¥ï‡µÜ\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.MALAYALAM,\n",
        "        \"lang_code_nllb\": \"mal_Mlym\",\n",
        "        \"normalizer\": \"ml\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Malayalam Preprocessing\n",
        "# =========================\n",
        "def preprocess_roman_malayalam(text):\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# =========================\n",
        "# Core Functions\n",
        "# =========================\n",
        "def transliterate_roman_to_native(text: str, lang: str) -> str:\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    out_tokens = []\n",
        "    for tok in tokens:\n",
        "        low = tok.lower()\n",
        "        mapped = config[\"code_mix_dict\"].get(low)\n",
        "        if mapped:\n",
        "            out_tokens.append(mapped)\n",
        "        elif lang == \"malayalam\":\n",
        "            out_tokens.append(tok)  # Only dict mapping for Malayalam\n",
        "        else:\n",
        "            try:\n",
        "                native = transliterate(tok, config[\"src_script\"], config[\"tgt_script\"])\n",
        "                if re.search(r\"[A-Za-z]\", native):\n",
        "                    out_tokens.append(tok)\n",
        "                else:\n",
        "                    out_tokens.append(native)\n",
        "            except Exception:\n",
        "                out_tokens.append(tok)\n",
        "    return \" \".join(out_tokens).strip()\n",
        "\n",
        "def normalize_native_text(text: str, lang: str) -> str:\n",
        "    normalizer = indic_normalize.IndicNormalizerFactory().get_normalizer(LANG_CONFIG[lang][\"normalizer\"])\n",
        "    normalized = normalizer.normalize(text)\n",
        "    if lang == \"hindi\":\n",
        "        normalized = normalized.replace(\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\").replace(\"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó\", \"‡§¨‡•à‡§†‡§ï\")\n",
        "    elif lang == \"bengali\":\n",
        "        normalized = normalized.replace(\"‡¶≠‡¶æ‡¶≤\", \"‡¶≠‡¶æ‡¶≤‡ßã\")\n",
        "    elif lang == \"marathi\":\n",
        "        normalized = normalized.replace(\"‡§õ‡•ç‡§π‡§æ‡§®\", \"‡§õ‡§æ‡§®\").replace(\"\\u200c\", \"\").replace(\"\\u200b\", \"\")\n",
        "    return re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "def detect_code_mixed_words(text: str, lang: str):\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    return [tok for tok in tokens if tok.lower() in config[\"code_mix_dict\"] or re.match(r\"^[A-Za-z]+$\", tok)]\n",
        "\n",
        "def translate_nllb(text, src_lang, tgt_lang):\n",
        "    tokenizer_nllb.src_lang = src_lang\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_lang_id = tokenizer_nllb.convert_tokens_to_ids(tgt_lang)\n",
        "    generated = model_nllb.generate(**encoded, forced_bos_token_id=tgt_lang_id)\n",
        "    return tokenizer_nllb.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "def full_pipeline(input_text: str, input_lang: str, target_langs: list):\n",
        "    print(f\"\\nü™Ñ Step 0: Input Text: {input_text}\")\n",
        "    if input_lang == \"malayalam\":\n",
        "        input_text = preprocess_roman_malayalam(input_text)\n",
        "    native_text = transliterate_roman_to_native(input_text, input_lang)\n",
        "    print(f\"üà∂ Step 1: After Transliteration: {native_text}\")\n",
        "    code_mix = detect_code_mixed_words(input_text, input_lang)\n",
        "    print(f\"üîç Step 2: Detected code-mixed words: {code_mix}\")\n",
        "    normalized_native = normalize_native_text(native_text, input_lang)\n",
        "    print(f\"ü™∂ Step 3: Normalized Text: {normalized_native}\")\n",
        "    english_text = translate_nllb(normalized_native, LANG_CONFIG[input_lang][\"lang_code_nllb\"], \"eng_Latn\")\n",
        "    print(f\"üá¨üáß Step 4: English Translation: {english_text}\")\n",
        "    translations = {LANG_CONFIG[input_lang][\"lang_code_nllb\"]: normalized_native, \"eng_Latn\": english_text}\n",
        "    print(\"\\nüåç Step 5: Translations to Other Languages:\")\n",
        "    for lang in target_langs:\n",
        "        lang_code = LANG_CONFIG[lang][\"lang_code_nllb\"]\n",
        "        translated_text = translate_nllb(english_text, \"eng_Latn\", lang_code)\n",
        "        translations[lang_code] = translated_text\n",
        "        print(f\"{lang_code}: {translated_text}\")\n",
        "    print(\"\\n‚úÖ Multilingual translation pipeline complete!\")\n",
        "    return translations\n",
        "\n",
        "# =========================\n",
        "# Example Usage\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Malayalam Example\n",
        "    INPUT_SENTENCE = \"ivide wifi signal valare weak aanu\"\n",
        "    INPUT_LANG = \"malayalam\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)\n",
        "\n",
        "    # Hindi Example\n",
        "    INPUT_SENTENCE2 = \"mujhe class ke baad meeting me aana hai\"\n",
        "    INPUT_LANG2 = \"hindi\"\n",
        "    TARGET_LANGUAGES2 = [\"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results2 = full_pipeline(INPUT_SENTENCE2, INPUT_LANG2, TARGET_LANGUAGES2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F3pm5N5bELtK",
        "outputId": "1359e9ce-274a-4d5f-c31c-aab1f3169cc8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: ivide wifi signal valare weak aanu\n",
            "üà∂ Step 1: After Transliteration: ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ wifi ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ ‡¥µ‡¥≥‡¥∞‡µÜ ‡¥µ‡µÄ‡¥ï‡µç ‡¥Ü‡¥£‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['ivide', 'wifi', 'signal', 'valare', 'weak', 'aanu']\n",
            "ü™∂ Step 3: Normalized Text: ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ wifi ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ ‡¥µ‡¥≥‡¥∞‡µÜ ‡¥µ‡µÄ‡¥ï‡µç ‡¥Ü‡¥£‡µç\n",
            "üá¨üáß Step 4: English Translation: The wifi signal is very weak here.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§µ‡§æ‡§à‡§´‡§æ‡§à ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§π‡•à ‡§Ø‡§π‡§æ‡§Å.\n",
            "tam_Taml: ‡Æµ‡Øà‡ÆÉ‡Æ™‡Øà ‡Æö‡ÆÆ‡Æø‡Æï‡Øç‡Æû‡Øà ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æ™‡Æ≤‡Æµ‡ØÄ‡Æ©‡ÆÆ‡Ææ‡Æï ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.\n",
            "tel_Telu: ‡∞µ‡±à‡∞´‡±à ‡∞∏‡∞ø‡∞ó‡±ç‡∞®‡∞≤‡±ç ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞¨‡∞≤‡∞π‡±Ä‡∞®‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§µ‡§æ‡§Ø‡§´‡§æ‡§Ø ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§ñ‡•Ç‡§™‡§ö ‡§ï‡§Æ‡§ï‡•Å‡§µ‡§§ ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤‡¶ü‡¶æ ‡¶ñ‡ßÅ‡¶¨ ‡¶¶‡ßÅ‡¶∞‡ßç‡¶¨‡¶≤‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n",
            "\n",
            "ü™Ñ Step 0: Input Text: mujhe class ke baad meeting me aana hai\n",
            "üà∂ Step 1: After Transliteration: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§¨‡•à‡§†‡§ï ‡§Æ‡•á‡§Ç ‡§Ü‡§®‡§æ ‡§π‡•à\n",
            "üîç Step 2: Detected code-mixed words: ['mujhe', 'class', 'ke', 'baad', 'meeting', 'me', 'aana', 'hai']\n",
            "ü™∂ Step 3: Normalized Text: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§¨‡•à‡§†‡§ï ‡§Æ‡•á‡§Ç ‡§Ü‡§®‡§æ ‡§π‡•à\n",
            "üá¨üáß Step 4: English Translation: I have to come to the meeting after class.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "tam_Taml: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æµ‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ ‡Æ™‡Æø‡Æ±‡Æï‡ØÅ ‡Æï‡ØÇ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æµ‡Æ∞ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç.\n",
            "tel_Telu: ‡∞®‡±á‡∞®‡±Å ‡∞§‡∞∞‡∞ó‡∞§‡∞ø ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞µ‡±á‡∞∂‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∞‡∞æ‡∞µ‡∞æ‡∞≤‡∞ø.\n",
            "mar_Deva: ‡§Æ‡§≤‡§æ ‡§µ‡§∞‡•ç‡§ó‡§æ‡§®‡§Ç‡§§‡§∞ ‡§¨‡•à‡§†‡§ï‡•Ä‡§≤‡§æ ‡§Ø‡•á‡§£‡§Ç ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶∂‡ßá‡¶∑‡ßá ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá ‡¶Ü‡¶∏‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## combination of  indic and facebook model\n",
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "# Try importing IndicTrans2 Toolkit\n",
        "try:\n",
        "    from IndicTransToolkit.processor import IndicProcessor\n",
        "    USE_INDIC_TRANS = True\n",
        "except ImportError:\n",
        "    USE_INDIC_TRANS = False\n",
        "\n",
        "# =========================\n",
        "# Device Setup\n",
        "# =========================\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================\n",
        "# Model Loading\n",
        "# =========================\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "if USE_INDIC_TRANS:\n",
        "    IT2_INDIC2EN = \"ai4bharat/indictrans2-indic-en-1B\"\n",
        "    IT2_EN2INDIC = \"ai4bharat/indictrans2-en-indic-1B\"\n",
        "    tokenizer_indic_en = AutoTokenizer.from_pretrained(IT2_INDIC2EN)\n",
        "    model_indic_en = AutoModelForSeq2SeqLM.from_pretrained(IT2_INDIC2EN).to(DEVICE)\n",
        "    tokenizer_en_indic = AutoTokenizer.from_pretrained(IT2_EN2INDIC)\n",
        "    model_en_indic = AutoModelForSeq2SeqLM.from_pretrained(IT2_EN2INDIC).to(DEVICE)\n",
        "    ip = IndicProcessor(inference=True)\n",
        "\n",
        "# =========================\n",
        "# Language Configurations\n",
        "# =========================\n",
        "# ... (same as your earlier LANG_CONFIG, including mapping dictionaries for all languages) ...\n",
        "\n",
        "# For brevity in this response, reuse your existing LANG_CONFIG as defined previously.\n",
        "\n",
        "# =========================\n",
        "# Preprocessing/Transliteration/Normalization Functions\n",
        "# =========================\n",
        "# ... (as previously but with robust mapping and fallback, see prior answers for details) ...\n",
        "\n",
        "# =========================\n",
        "# Hybrid Translation Functions\n",
        "# =========================\n",
        "\n",
        "def indictrans_translate(text, src_lang_tag, tgt_lang_tag, direction=\"indic_to_en\"):\n",
        "    \"\"\"Translate using IndicTrans2\"\"\"\n",
        "    if not USE_INDIC_TRANS:\n",
        "        raise Exception(\"IndicTrans2 not installed.\")\n",
        "    batch = ip.preprocess_batch([text], src_lang=src_lang_tag, tgt_lang=tgt_lang_tag)\n",
        "    if direction == \"indic_to_en\":\n",
        "        model, tokenizer = model_indic_en, tokenizer_indic_en\n",
        "    else:\n",
        "        model, tokenizer = model_en_indic, tokenizer_en_indic\n",
        "    inputs = tokenizer(batch, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            num_beams=5,\n",
        "            early_stopping=True,\n",
        "            max_length=256,\n",
        "            use_cache=False\n",
        "        )\n",
        "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    translations = ip.postprocess_batch(decoded, lang=tgt_lang_tag)\n",
        "    return translations[0]\n",
        "\n",
        "def nllb_translate(text, src_lang, tgt_lang):\n",
        "    \"\"\"Translate using NLLB (fine-tuned or off-the-shelf)\"\"\"\n",
        "    tokenizer_nllb.src_lang = src_lang\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_lang_id = tokenizer_nllb.convert_tokens_to_ids(tgt_lang)\n",
        "    generated = model_nllb.generate(**encoded, forced_bos_token_id=tgt_lang_id)\n",
        "    return tokenizer_nllb.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "def hybrid_translate(text, input_lang, target_lang, use_indictrans_first=True, return_english=False):\n",
        "    \"\"\"\n",
        "    Use IndicTrans2 for Indian language pairs, fallback to NLLB for English or other cases.\n",
        "    If return_english=True, returns a tuple: (english, final)\n",
        "    \"\"\"\n",
        "    src_code = LANG_CONFIG[input_lang][\"lang_code_nllb\"] if input_lang != \"english\" else \"eng_Latn\"\n",
        "    tgt_code = LANG_CONFIG[target_lang][\"lang_code_nllb\"] if target_lang != \"english\" else \"eng_Latn\"\n",
        "    try:\n",
        "        normalized_text = normalize_native_text(transliterate_roman_to_native(text, input_lang), input_lang) if input_lang != \"english\" else text\n",
        "        if USE_INDIC_TRANS and input_lang != \"english\" and target_lang != \"english\" and use_indictrans_first:\n",
        "            # Native ‚Üí English ‚Üí Native\n",
        "            english = indictrans_translate(normalized_text, src_code, \"eng_Latn\", direction=\"indic_to_en\")\n",
        "            final = indictrans_translate(english, \"eng_Latn\", tgt_code, direction=\"en_to_indic\")\n",
        "            if return_english:\n",
        "                return english, final\n",
        "            return final\n",
        "        elif input_lang != \"english\" and target_lang == \"english\":\n",
        "            # Native ‚Üí English\n",
        "            if USE_INDIC_TRANS:\n",
        "                english = indictrans_translate(normalized_text, src_code, \"eng_Latn\", direction=\"indic_to_en\")\n",
        "                return english\n",
        "            else:\n",
        "                return nllb_translate(normalized_text, src_code, \"eng_Latn\")\n",
        "        elif input_lang == \"english\" and target_lang != \"english\":\n",
        "            # English ‚Üí Native\n",
        "            if USE_INDIC_TRANS:\n",
        "                final = indictrans_translate(text, \"eng_Latn\", tgt_code, direction=\"en_to_indic\")\n",
        "                return final\n",
        "            else:\n",
        "                return nllb_translate(text, \"eng_Latn\", tgt_code)\n",
        "        else:\n",
        "            # Direct NLLB or fallback\n",
        "            final = nllb_translate(normalized_text, src_code, tgt_code)\n",
        "            if return_english:\n",
        "                return None, final\n",
        "            return final\n",
        "    except Exception as e:\n",
        "        print(f\"Hybrid translation error: {e}\")\n",
        "        # Fallback to direct NLLB\n",
        "        final = nllb_translate(text, src_code, tgt_code)\n",
        "        if return_english:\n",
        "            return None, final\n",
        "        return final\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Example Usage\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    sample_sentences = [\n",
        "        (\"ivide wifi signal valare weak aanu\", \"malayalam\", [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]),\n",
        "        (\"mujhe class ke baad meeting me aana hai\", \"hindi\", [\"tamil\", \"telugu\", \"marathi\", \"bengali\", \"malayalam\"]),\n",
        "        (\"nee laptop vaangi irukka\", \"tamil\", [\"hindi\", \"telugu\", \"marathi\", \"bengali\", \"malayalam\"]),\n",
        "        # add more as needed\n",
        "    ]\n",
        "    for sent, in_lang, targets in sample_sentences:\n",
        "        for tgt in targets:\n",
        "            print(f\"\\nüü¢ Translating '{sent}' [{in_lang}] ‚Üí [{tgt}]\")\n",
        "            result = hybrid_translate(sent, in_lang, tgt)\n",
        "            print(f\"[{tgt}]: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m1qOahj_EzC6",
        "outputId": "18699be2-ad54-4219-b004-65d3db2d53e0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üü¢ Translating 'ivide wifi signal valare weak aanu' [malayalam] ‚Üí [hindi]\n",
            "[hindi]: ‡§µ‡§æ‡§à‡§´‡§æ‡§à ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§π‡§°‡§º‡§§‡§æ‡§≤‡•Ä ‡§π‡•à\n",
            "\n",
            "üü¢ Translating 'ivide wifi signal valare weak aanu' [malayalam] ‚Üí [tamil]\n",
            "[tamil]: ‡Æá‡Æô‡Øç‡Æï‡Øá ‡Æµ‡Øà‡ÆÉ‡Æ™‡Øà ‡Æö‡ÆÆ‡Æø‡Æï‡Øç‡Æû‡Øà ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æµ‡Æø‡ÆØ‡Æï‡Øç‡Æï‡Æ§‡Øç‡Æ§‡Æï‡Øç‡Æï‡Æ§‡ØÅ\n",
            "\n",
            "üü¢ Translating 'ivide wifi signal valare weak aanu' [malayalam] ‚Üí [telugu]\n",
            "[telugu]: ‡∞á‡∞ï‡±ç‡∞ï‡∞° ‡∞µ‡±à‡∞´‡±à ‡∞∏‡∞ø‡∞ó‡±ç‡∞®‡∞≤‡±ç ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞µ‡±Ä‡∞ï‡±ç ‡∞â‡∞Ç‡∞¶‡∞ø\n",
            "\n",
            "üü¢ Translating 'ivide wifi signal valare weak aanu' [malayalam] ‚Üí [marathi]\n",
            "[marathi]: ‡§Ø‡•á‡§•‡•á ‡§µ‡§æ‡§Ø‡§´‡§æ‡§Ø ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§ñ‡•Ç‡§™‡§ö ‡§ó‡•ã‡§Ç‡§ß‡§≥‡§æ‡§§ ‡§Ü‡§π‡•á\n",
            "\n",
            "üü¢ Translating 'ivide wifi signal valare weak aanu' [malayalam] ‚Üí [bengali]\n",
            "[bengali]: ‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ñ‡ßÅ‡¶¨ ‡¶ö‡¶∞‡¶Æ\n",
            "\n",
            "üü¢ Translating 'mujhe class ke baad meeting me aana hai' [hindi] ‚Üí [tamil]\n",
            "[tamil]: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æµ‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ ‡Æ™‡Æø‡Æ±‡Æï‡ØÅ ‡Æï‡ØÇ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æµ‡Æ∞ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç\n",
            "\n",
            "üü¢ Translating 'mujhe class ke baad meeting me aana hai' [hindi] ‚Üí [telugu]\n",
            "[telugu]: ‡∞®‡±á‡∞®‡±Å ‡∞§‡∞∞‡∞ó‡∞§‡∞ø ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞µ‡±á‡∞∂‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∞‡∞æ‡∞µ‡∞æ‡∞≤‡∞ø\n",
            "\n",
            "üü¢ Translating 'mujhe class ke baad meeting me aana hai' [hindi] ‚Üí [marathi]\n",
            "[marathi]: ‡§Æ‡§≤‡§æ ‡§µ‡§∞‡•ç‡§ó‡§æ‡§®‡§Ç‡§§‡§∞ ‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó‡§≤‡§æ ‡§Ø‡•á‡§£‡•á ‡§Ü‡§π‡•á.\n",
            "\n",
            "üü¢ Translating 'mujhe class ke baad meeting me aana hai' [hindi] ‚Üí [bengali]\n",
            "[bengali]: ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ ‡¶™‡¶∞ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶è ‡¶Ü‡¶∏‡¶§‡ßá ‡¶π‡¶¨‡ßá\n",
            "\n",
            "üü¢ Translating 'mujhe class ke baad meeting me aana hai' [hindi] ‚Üí [malayalam]\n",
            "[malayalam]: ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥ï‡µç‡¥≤‡¥æ‡¥∏‡µç ‡¥ï‡¥¥‡¥ø‡¥û‡µç‡¥û‡¥æ‡µΩ ‡¥Æ‡µÄ‡¥±‡µç‡¥±‡¥ø‡¥Ç‡¥ó‡¥ø‡µΩ ‡¥µ‡¥∞‡¥£‡¥Ç.\n",
            "\n",
            "üü¢ Translating 'nee laptop vaangi irukka' [tamil] ‚Üí [hindi]\n",
            "[hindi]: ‡§Ü‡§™ ‡§≤‡§æ‡§§‡•ç‡§∞‡•ã‡§™ ‡§µ‡•à‡§Ç‡§ï‡•Ä ‡§π‡•ã\n",
            "\n",
            "üü¢ Translating 'nee laptop vaangi irukka' [tamil] ‚Üí [telugu]\n",
            "[telugu]: ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞≤‡∞æ‡∞•‡±ã‡∞™‡±ç ‡∞µ‡∞æ‡∞Ç‡∞ï‡±Ä ‡∞â‡∞Ç‡∞°‡∞æ‡∞≤‡∞ø\n",
            "\n",
            "üü¢ Translating 'nee laptop vaangi irukka' [tamil] ‚Üí [marathi]\n",
            "[marathi]: ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§≤‡•Ö‡§™‡§ü‡•â‡§™ ‡§µ‡•Ö‡§®‡•ç‡§ï‡•Ä ‡§Ü‡§π‡§æ‡§§\n",
            "\n",
            "üü¢ Translating 'nee laptop vaangi irukka' [tamil] ‚Üí [bengali]\n",
            "[bengali]: ‡¶Ü‡¶™‡¶®‡¶ø ‡¶≤‡¶æ‡¶°‡ßã‡¶¨ ‡¶≠‡ßç‡¶Ø‡¶æ‡¶®‡¶ï‡¶ø ‡¶π‡¶§‡ßá\n",
            "\n",
            "üü¢ Translating 'nee laptop vaangi irukka' [tamil] ‚Üí [malayalam]\n",
            "[malayalam]: ‡¥≤‡¥æ‡¥°‡µã‡¥™‡µç‡¥™‡µç ‡¥µ‡¥æ‡µª‡¥ï‡¥ø ‡¥Ü‡¥Ø‡¥ø‡¥∞‡µÅ‡¥®‡µç‡¥®‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    sample_sentences = [\n",
        "        (\"nenu cinema ki vellali\", \"telugu\", [\"hindi\", \"marathi\", \"bengali\", \"tamil\", \"malayalam\"]),\n",
        "        (\"mi office la jaato nahi\", \"marathi\", [\"hindi\", \"telugu\", \"tamil\", \"bengali\", \"malayalam\"]),\n",
        "        (\"kal amar friend asche office e\", \"bengali\", [\"hindi\", \"marathi\", \"telugu\", \"tamil\", \"malayalam\"]),\n",
        "        (\"main kal party attend karunga\", \"hindi\", [\"tamil\", \"telugu\", \"marathi\", \"bengali\", \"malayalam\"]),\n",
        "        (\"naan school-ku poganum\", \"tamil\", [\"hindi\", \"telugu\", \"marathi\", \"bengali\", \"malayalam\"]),\n",
        "        (\"innale padam kandittu super aanu\", \"malayalam\", [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]),\n",
        "    ]\n",
        "    for sent, in_lang, targets in sample_sentences:\n",
        "        for tgt in targets:\n",
        "            print(f\"\\nüü¢ Translating '{sent}' [{in_lang}] ‚Üí [{tgt}]\")\n",
        "            result = hybrid_translate(sent, in_lang, tgt)\n",
        "            print(f\"[{tgt}]: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iDzNBpeuFDcK",
        "outputId": "1a42ffca-2e9c-4d51-94f5-b3c03ee00d7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üü¢ Translating 'nenu cinema ki vellali' [telugu] ‚Üí [hindi]\n",
            "[hindi]: ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ø‡§®‡•á‡§Æ‡§æ ‡§ú‡§æ‡§®‡§æ ‡§π‡•à\n",
            "\n",
            "üü¢ Translating 'nenu cinema ki vellali' [telugu] ‚Üí [marathi]\n",
            "[marathi]: ‡§Æ‡§≤‡§æ ‡§ö‡§ø‡§®‡•á‡§Æ‡§æ‡§≤‡§æ ‡§ú‡§æ‡§Ø‡§ö‡§Ç ‡§Ü‡§π‡•á.\n",
            "\n",
            "üü¢ Translating 'nenu cinema ki vellali' [telugu] ‚Üí [bengali]\n",
            "[bengali]: ‡¶Ü‡¶Æ‡¶ø ‡¶ö‡¶æ‡¶á‡¶®‡ßá‡¶Æ‡¶æ ‡¶Ø‡ßá‡¶§‡ßá ‡¶π‡¶¨‡ßá\n",
            "\n",
            "üü¢ Translating 'nenu cinema ki vellali' [telugu] ‚Üí [tamil]\n",
            "[tamil]: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æö‡Æø‡Æ©‡Øá‡ÆÆ‡Ææ ‡Æö‡ØÜ‡Æ≤‡Øç‡Æ≤ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç\n",
            "\n",
            "üü¢ Translating 'nenu cinema ki vellali' [telugu] ‚Üí [malayalam]\n",
            "[malayalam]: ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥ö‡¥ø‡¥®‡µá‡¥Æ‡¥Ø‡¥ø‡¥≤‡µá‡¥ï‡µç‡¥ï‡µç ‡¥™‡µã‡¥ï‡¥£‡¥Ç.\n",
            "\n",
            "üü¢ Translating 'mi office la jaato nahi' [marathi] ‚Üí [hindi]\n",
            "[hindi]: ‡§Æ‡•à‡§Ç ‡§ë‡§´‡§ø‡§∏ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡§æ‡§§‡§æ‡•§\n",
            "\n",
            "üü¢ Translating 'mi office la jaato nahi' [marathi] ‚Üí [telugu]\n",
            "[telugu]: ‡∞®‡±á‡∞®‡±Å ‡∞Ü‡∞´‡±Ä‡∞∏‡±Å‡∞ï‡∞ø ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞®‡±Å.\n",
            "\n",
            "üü¢ Translating 'mi office la jaato nahi' [marathi] ‚Üí [tamil]\n",
            "[tamil]: ‡Æ®‡Ææ‡Æ©‡Øç ‡ÆÖ‡Æ≤‡ØÅ‡Æµ‡Æ≤‡Æï‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æö‡ØÜ‡Æ≤‡Øç‡Æ≤ ‡ÆÆ‡Ææ‡Æü‡Øç‡Æü‡Øá‡Æ©‡Øç.\n",
            "\n",
            "üü¢ Translating 'mi office la jaato nahi' [marathi] ‚Üí [bengali]\n",
            "[bengali]: ‡¶Ü‡¶Æ‡¶ø ‡¶Ö‡¶´‡¶ø‡¶∏‡ßá ‡¶Ø‡¶æ‡¶á ‡¶®‡¶æ‡•§\n",
            "\n",
            "üü¢ Translating 'mi office la jaato nahi' [marathi] ‚Üí [malayalam]\n",
            "[malayalam]: ‡¥û‡¥æ‡µª ‡¥ì‡¥´‡µÄ‡¥∏‡¥ø‡µΩ ‡¥™‡µã‡¥ï‡µÅ‡¥®‡µç‡¥®‡¥ø‡¥≤‡µç‡¥≤.\n",
            "\n",
            "üü¢ Translating 'kal amar friend asche office e' [bengali] ‚Üí [hindi]\n",
            "[hindi]: ‡§Æ‡•á‡§∞‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§¨‡•Å‡§≤‡§æ‡§Ø‡§æ\n",
            "\n",
            "üü¢ Translating 'kal amar friend asche office e' [bengali] ‚Üí [marathi]\n",
            "[marathi]: ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§´‡•ç‡§∞‡•á‡§Ç‡§°‡§≤‡§æ ‡§´‡•ã‡§® ‡§Ü‡§≤‡§æ.\n",
            "\n",
            "üü¢ Translating 'kal amar friend asche office e' [bengali] ‚Üí [telugu]\n",
            "[telugu]: ‡∞®‡∞æ ‡∞´‡±ç‡∞∞‡±Ü‡∞Ç‡∞°‡±ç ‡∞ï‡∞æ‡∞≤‡±ç‡∞∏‡±ç ‡∞ì‡∞´‡±ç‡∞´‡∞æ‡∞ö‡±ç ‡∞≤‡±ã ‡∞µ‡∞ö‡±ç‡∞ö‡∞æ‡∞Ø‡∞ø\n",
            "\n",
            "üü¢ Translating 'kal amar friend asche office e' [bengali] ‚Üí [tamil]\n",
            "[tamil]: ‡Æé‡Æ©‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æ£‡Øç‡Æü‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ‡Æ™‡Øç‡Æ∞‡ØÄ‡Æö‡Øç ‡ÆÉ\n",
            "\n",
            "üü¢ Translating 'kal amar friend asche office e' [bengali] ‚Üí [malayalam]\n",
            "[malayalam]: ‡¥é‡¥®‡µç‡¥±‡µÜ ‡¥´‡µç‡¥∞‡¥£‡µç‡¥ü‡µç ‡¥ì‡¥´‡µç‡¥´‡µÄ‡¥ö‡µç‡¥ö‡¥ø‡µΩ ‡¥µ‡¥ø‡¥≥‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.\n",
            "\n",
            "üü¢ Translating 'main kal party attend karunga' [hindi] ‚Üí [tamil]\n",
            "[tamil]: ‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æ©‡Øç‡Æ©‡Øà ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æï‡Æø‡Æ∞‡ØÅ‡Æ™‡Øà‡ÆØ‡ØÅ‡Æü‡Æ©‡Øç\n",
            "\n",
            "üü¢ Translating 'main kal party attend karunga' [hindi] ‚Üí [telugu]\n",
            "[telugu]: ‡∞®‡±á‡∞®‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞ï‡∞∞‡±Å‡∞£‡∞ø‡∞Ç‡∞ö‡∞æ‡∞®‡±Å\n",
            "\n",
            "üü¢ Translating 'main kal party attend karunga' [hindi] ‚Üí [marathi]\n",
            "[marathi]: ‡§Æ‡•Ä ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§ñ‡•Ç‡§™ ‡§™‡•ç‡§∞‡•á‡§Æ ‡§ï‡§∞‡§§‡•ã.\n",
            "\n",
            "üü¢ Translating 'main kal party attend karunga' [hindi] ‚Üí [bengali]\n",
            "[bengali]: ‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ï‡¶≤ ‡¶™‡¶æ‡¶∞‡ßç‡¶§‡ßá ‡¶è‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶£\n",
            "\n",
            "üü¢ Translating 'main kal party attend karunga' [hindi] ‚Üí [malayalam]\n",
            "[malayalam]: ‡¥û‡¥æ‡µª ‡¥é‡¥®‡µç‡¥®‡µÜ‡¥§‡µç‡¥§‡¥®‡µç‡¥®‡µÜ ‡¥∏‡µç‡¥®‡µá‡¥π‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.\n",
            "\n",
            "üü¢ Translating 'naan school-ku poganum' [tamil] ‚Üí [hindi]\n",
            "[hindi]: ‡§Æ‡•Å‡§ù‡•á ‡§∏‡•Ç‡§≤ ‡§ú‡§æ‡§®‡§æ ‡§π‡•à\n",
            "\n",
            "üü¢ Translating 'naan school-ku poganum' [tamil] ‚Üí [telugu]\n",
            "[telugu]: ‡∞®‡±á‡∞®‡±Å ‡∞∏‡±Å‡∞≤‡±ç‡∞ï‡±Å ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\n",
            "\n",
            "üü¢ Translating 'naan school-ku poganum' [tamil] ‚Üí [marathi]\n",
            "[marathi]: ‡§Æ‡§≤‡§æ ‡§∏‡•Ç‡§≤‡§≤‡§æ ‡§ú‡§æ‡§Ø‡§ö‡§Ç ‡§Ü‡§π‡•á.\n",
            "\n",
            "üü¢ Translating 'naan school-ku poganum' [tamil] ‚Üí [bengali]\n",
            "[bengali]: ‡¶Ü‡¶Æ‡¶ø ‡¶∏‡ßÅ‡¶≤ ‡¶Ø‡ßá‡¶§‡ßá ‡¶ö‡¶æ‡¶á\n",
            "\n",
            "üü¢ Translating 'naan school-ku poganum' [tamil] ‚Üí [malayalam]\n",
            "[malayalam]: ‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥∏‡µç‡¥Ø‡µÇ‡¥≥‡¥ø‡µΩ ‡¥™‡µã‡¥ï‡¥£‡¥Ç.\n",
            "\n",
            "üü¢ Translating 'innale padam kandittu super aanu' [malayalam] ‚Üí [hindi]\n",
            "[hindi]: ‡§ï‡§≤ ‡§ï‡•Ä ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡§æ\n",
            "\n",
            "üü¢ Translating 'innale padam kandittu super aanu' [malayalam] ‚Üí [tamil]\n",
            "[tamil]: ‡Æ®‡Øá‡Æ±‡Øç‡Æ±‡ØÅ ‡Æ™‡Æü‡ÆÆ‡Øç ‡Æ™‡Ææ‡Æ∞‡Øç‡Æ§‡Øç‡Æ§‡Æ§‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ∞‡ØÅ‡ÆÆ‡Øà‡ÆØ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡Æ§‡ØÅ.\n",
            "\n",
            "üü¢ Translating 'innale padam kandittu super aanu' [malayalam] ‚Üí [telugu]\n",
            "[telugu]: ‡∞®‡∞ø‡∞®‡±ç‡∞®‡∞ü‡∞ø ‡∞∏‡∞ø‡∞®‡∞ø‡∞Æ‡∞æ ‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±á ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞¨‡∞æ‡∞ó‡±Å‡∞Ç‡∞¶‡∞ø.\n",
            "\n",
            "üü¢ Translating 'innale padam kandittu super aanu' [malayalam] ‚Üí [marathi]\n",
            "[marathi]: ‡§ï‡§æ‡§≤‡§ö‡§æ ‡§ö‡§ø‡§§‡•ç‡§∞‡§™‡§ü ‡§™‡§æ‡§π‡§ø‡§≤‡•ç‡§Ø‡§æ‡§®‡§Ç‡§§‡§∞ ‡§ñ‡•Ç‡§™ ‡§õ‡§æ‡§® ‡§Ü‡§π‡•á.\n",
            "\n",
            "üü¢ Translating 'innale padam kandittu super aanu' [malayalam] ‚Üí [bengali]\n",
            "[bengali]: ‡¶ó‡¶§‡¶ï‡¶æ‡¶≤‡ßá‡¶∞ ‡¶õ‡¶¨‡¶ø‡¶ü‡¶æ ‡¶¶‡ßá‡¶ñ‡ßá ‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶≤‡¶æ‡¶ó‡¶õ‡ßá‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##includes malayalam also knchm accurate\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "LANG_CONFIG = {\n",
        "    \"hindi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            # Add more coverage here\n",
        "            \"class\": \"‡§ï‡§ï‡•ç‡§∑‡§æ\", \"meeting\": \"‡§¨‡•à‡§†‡§ï\", \"me\": \"‡§Æ‡•á‡§Ç\", \"after\": \"‡§¨‡§æ‡§¶\", \"ke\": \"‡§ï‡•á\", \"baad\": \"‡§¨‡§æ‡§¶\",\n",
        "            \"aana\": \"‡§Ü‡§®‡§æ\", \"hai\": \"‡§π‡•à\", \"mujhe\": \"‡§Æ‡•Å‡§ù‡•á\", \"please\": \"‡§ï‡•É‡§™‡§Ø‡§æ\", \"sir\": \"‡§∏‡§æ‡§π‡§¨\", \"madam\": \"‡§Æ‡•à‡§°‡§Æ\",\n",
        "            \"office\": \"‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø\", \"wifi\": \"‡§µ‡§æ‡§à-‡§´‡§æ‡§à\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"hin_Deva\",\n",
        "        \"normalizer\": \"hi\"\n",
        "    },\n",
        "    \"tamil\": {\n",
        "        \"code_mix_dict\": {\n",
        "            # Add more coverage here\n",
        "            \"naan\": \"‡Æ®‡Ææ‡Æ©‡Øç\", \"nee\": \"‡Æ®‡ØÄ\", \"class\": \"‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç\", \"ku\": \"‡Æï‡Øç‡Æï‡ØÅ\", \"poganum\": \"‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"ponanum\": \"‡Æ™‡Øã‡Æµ‡Øá‡Æ©‡Øç\", \"varanum\": \"‡Æµ‡Æ∞‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"sollanum\": \"‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"pananum\": \"‡Æ™‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"office\": \"‡ÆÖ‡Æ≤‡ØÅ‡Æµ‡Æ≤‡Æï‡ÆÆ‡Øç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TAMIL,\n",
        "        \"lang_code_nllb\": \"tam_Taml\",\n",
        "        \"normalizer\": \"ta\"\n",
        "    },\n",
        "    \"telugu\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"class\": \"‡∞§‡∞∞‡∞ó‡∞§‡∞ø\", \"vellali\": \"‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\", \"office\": \"‡∞Ü‡∞´‡±Ä‡∞∏‡±ç\", \"wifi\": \"‡∞µ‡±à‡∞´‡±à\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TELUGU,\n",
        "        \"lang_code_nllb\": \"tel_Telu\",\n",
        "        \"normalizer\": \"te\"\n",
        "    },\n",
        "    \"marathi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"tu\": \"‡§§‡•Ç\", \"tula\": \"‡§§‡•Å‡§≤‡§æ\", \"kasa\": \"‡§ï‡§∏‡§æ\", \"majha\": \"‡§Æ‡§æ‡§ù‡§æ\", \"office\": \"‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø\",\n",
        "            \"wifi\": \"‡§µ‡§æ‡§à-‡§´‡§æ‡§à\", \"school\": \"‡§∂‡§æ‡§≥‡§æ\", \"nahi\": \"‡§®‡§æ‡§π‡•Ä\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"mar_Deva\",\n",
        "        \"normalizer\": \"mr\"\n",
        "    },\n",
        "    \"bengali\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"ami\": \"‡¶Ü‡¶Æ‡¶ø\", \"tumi\": \"‡¶§‡ßÅ‡¶Æ‡¶ø\", \"office\": \"‡¶Ö‡¶´‡¶ø‡¶∏\", \"wifi\": \"‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.BENGALI,\n",
        "        \"lang_code_nllb\": \"ben_Beng\",\n",
        "        \"normalizer\": \"bn\"\n",
        "    },\n",
        "    \"malayalam\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"nee\": \"‡¥®‡µÄ\", \"lunch\": \"‡¥≤‡¥û‡µç‡¥ö‡µç\", \"signal\": \"‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ\", \"wifi\": \"‡¥µ‡µà‡¥´‡µà\", \"office\": \"‡¥ì‡¥´‡µÄ‡¥∏‡µç\",\n",
        "            \"week\": \"‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡µç\", \"aanu\": \"‡¥Ü‡¥£‡µç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.MALAYALAM,\n",
        "        \"lang_code_nllb\": \"mal_Mlym\",\n",
        "        \"normalizer\": \"ml\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def preprocess_roman_malayalam(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "def transliterate_roman_to_native(text: str, lang: str) -> str:\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    out_tokens = []\n",
        "    for tok in tokens:\n",
        "        low = tok.lower()\n",
        "        mapped = config[\"code_mix_dict\"].get(low)\n",
        "        if mapped:\n",
        "            out_tokens.append(mapped)\n",
        "        else:\n",
        "            if lang == \"malayalam\":\n",
        "                out_tokens.append(tok)\n",
        "            else:\n",
        "                try:\n",
        "                    native = transliterate(tok, config[\"src_script\"], config[\"tgt_script\"])\n",
        "                    if re.search(r\"[A-Za-z]\", native):\n",
        "                        out_tokens.append(tok)\n",
        "                    else:\n",
        "                        out_tokens.append(native)\n",
        "                except Exception:\n",
        "                    out_tokens.append(tok)\n",
        "    return \" \".join(out_tokens).strip()\n",
        "\n",
        "def normalize_native_text(text: str, lang: str) -> str:\n",
        "    normalizer = indic_normalize.IndicNormalizerFactory().get_normalizer(LANG_CONFIG[lang][\"normalizer\"])\n",
        "    normalized = normalizer.normalize(text)\n",
        "    if lang == \"hindi\":\n",
        "        normalized = normalized.replace(\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\").replace(\"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó\", \"‡§¨‡•à‡§†‡§ï\")\n",
        "    elif lang == \"bengali\":\n",
        "        normalized = normalized.replace(\"‡¶≠‡¶æ‡¶≤\", \"‡¶≠‡¶æ‡¶≤‡ßã\")\n",
        "    elif lang == \"marathi\":\n",
        "        normalized = normalized.replace(\"‡§õ‡•ç‡§π‡§æ‡§®\", \"‡§õ‡§æ‡§®\").replace(\"\\u200c\", \"\").replace(\"\\u200b\", \"\")\n",
        "    return re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "def detect_code_mixed_words(text: str, lang: str):\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, flags=re.UNICODE)\n",
        "    return [tok for tok in tokens if tok.lower() in config[\"code_mix_dict\"] or re.match(r\"^[A-Za-z]+$\", tok)]\n",
        "\n",
        "def translate_nllb(text, src_lang, tgt_lang):\n",
        "    tokenizer_nllb.src_lang = src_lang\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_lang_id = tokenizer_nllb.convert_tokens_to_ids(tgt_lang)\n",
        "    generated = model_nllb.generate(**encoded, forced_bos_token_id=tgt_lang_id)\n",
        "    return tokenizer_nllb.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "def full_pipeline(input_text: str, input_lang: str, target_langs: list):\n",
        "    print(f\"\\nü™Ñ Step 0: Input Text: {input_text}\")\n",
        "\n",
        "    if input_lang == \"malayalam\":\n",
        "        input_text = preprocess_roman_malayalam(input_text)\n",
        "\n",
        "    native_text = transliterate_roman_to_native(input_text, input_lang)\n",
        "    print(f\"üà∂ Step 1: After Transliteration: {native_text}\")\n",
        "\n",
        "    code_mix = detect_code_mixed_words(input_text, input_lang)\n",
        "    print(f\"üîç Step 2: Detected code-mixed words: {code_mix}\")\n",
        "\n",
        "    normalized_native = normalize_native_text(native_text, input_lang)\n",
        "    print(f\"ü™∂ Step 3: Normalized Text: {normalized_native}\")\n",
        "\n",
        "    english_text = translate_nllb(normalized_native, LANG_CONFIG[input_lang][\"lang_code_nllb\"], \"eng_Latn\")\n",
        "    print(f\"üá¨üáß Step 4: English Translation: {english_text}\")\n",
        "\n",
        "    translations = {LANG_CONFIG[input_lang][\"lang_code_nllb\"]: normalized_native, \"eng_Latn\": english_text}\n",
        "    print(\"\\nüåç Step 5: Translations to Other Languages:\")\n",
        "    for lang in target_langs:\n",
        "        lang_code = LANG_CONFIG[lang][\"lang_code_nllb\"]\n",
        "        translated_text = translate_nllb(english_text, \"eng_Latn\", lang_code)\n",
        "        translations[lang_code] = translated_text\n",
        "        print(f\"{lang_code}: {translated_text}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Multilingual translation pipeline complete!\")\n",
        "    return translations\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    INPUT_SENTENCE = \"ivide wifi signal valare weak aanu\"\n",
        "    INPUT_LANG = \"malayalam\"  # change as needed\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FErN5QMsZNDW",
        "outputId": "1ebb1637-eb77-425c-f9df-2b202e85d2b6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: ivide wifi signal valare weak aanu\n",
            "üà∂ Step 1: After Transliteration: ivide ‡¥µ‡µà‡¥´‡µà ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ valare weak ‡¥Ü‡¥£‡µç\n",
            "üîç Step 2: Detected code-mixed words: ['ivide', 'wifi', 'signal', 'valare', 'weak', 'aanu']\n",
            "ü™∂ Step 3: Normalized Text: ivide ‡¥µ‡µà‡¥´‡µà ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ valare weak ‡¥Ü‡¥£‡µç\n",
            "üá¨üáß Step 4: English Translation: The wifi signal is weak.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§µ‡§æ‡§à‡§´‡§æ‡§à ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§ï‡§Æ‡§ú‡•ã‡§∞ ‡§π‡•à‡•§\n",
            "tam_Taml: ‡Æµ‡Øà‡ÆÉ‡Æ™‡Øà ‡Æö‡ÆÆ‡Æø‡Æï‡Øç‡Æû‡Øà ‡Æ™‡Æ≤‡Æµ‡ØÄ‡Æ©‡ÆÆ‡Ææ‡Æï ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.\n",
            "tel_Telu: ‡∞µ‡±à‡∞´‡±à ‡∞∏‡∞ø‡∞ó‡±ç‡∞®‡∞≤‡±ç ‡∞¨‡∞≤‡∞π‡±Ä‡∞®‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§µ‡§æ‡§Ø‡§´‡§æ‡§Ø ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤ ‡§ï‡§Æ‡§ï‡•Å‡§µ‡§§ ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤‡¶ü‡¶æ ‡¶¶‡ßÅ‡¶∞‡ßç‡¶¨‡¶≤‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    INPUT_SENTENCE = \"ente phone battery ippo almost empty aanu.\"\n",
        "    INPUT_LANG = \"malayalam\"  # change as needed\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"bengali\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RBiPbBPYcbSa",
        "outputId": "f50c1ec1-d1b0-4791-f157-71862313464a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü™Ñ Step 0: Input Text: ente phone battery ippo almost empty aanu.\n",
            "üà∂ Step 1: After Transliteration: ente phone battery ippo almost empty ‡¥Ü‡¥£‡µç .\n",
            "üîç Step 2: Detected code-mixed words: ['ente', 'phone', 'battery', 'ippo', 'almost', 'empty', 'aanu']\n",
            "ü™∂ Step 3: Normalized Text: ente phone battery ippo almost empty ‡¥Ü‡¥£‡µç .\n",
            "üá¨üáß Step 4: English Translation: The phone battery ippo is almost empty.\n",
            "\n",
            "üåç Step 5: Translations to Other Languages:\n",
            "hin_Deva: ‡§´‡•ã‡§® ‡§ï‡•Ä ‡§¨‡•à‡§ü‡§∞‡•Ä ‡§≤‡§ó‡§≠‡§ó ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•à‡•§\n",
            "tam_Taml: ‡Æ§‡Øä‡Æ≤‡Øà‡Æ™‡Øá‡Æö‡Æø ‡Æ™‡Øá‡Æü‡Øç‡Æü‡Æ∞‡Æø ‡Æê‡Æ™‡Øã ‡Æï‡Æø‡Æü‡Øç‡Æü‡Æ§‡Øç‡Æ§‡Æü‡Øç‡Æü ‡Æï‡Ææ‡Æ≤‡Æø‡ÆØ‡Ææ‡Æï ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.\n",
            "tel_Telu: ‡∞´‡±ã‡∞®‡±ç ‡∞¨‡±ç‡∞Ø‡∞æ‡∞ü‡∞∞‡±Ä ‡∞ê‡∞™‡∞ø‡∞í ‡∞¶‡∞æ‡∞¶‡∞æ‡∞™‡±Å ‡∞ñ‡∞æ‡∞≥‡±Ä‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\n",
            "mar_Deva: ‡§´‡•ã‡§® ‡§¨‡•Ö‡§ü‡§∞‡•Ä ‡§Ü‡§Ø‡§™‡•Ä‡§ì ‡§ú‡§µ‡§≥‡§ú‡§µ‡§≥ ‡§∞‡§ø‡§ï‡•ç‡§§ ‡§Ü‡§π‡•á.\n",
            "ben_Beng: ‡¶´‡ßã‡¶®‡ßá‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ü‡¶æ‡¶∞‡¶ø ‡¶Ü‡¶á‡¶™‡¶ø‡¶ì ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶ñ‡¶æ‡¶≤‡¶ø‡•§\n",
            "\n",
            "‚úÖ Multilingual translation pipeline complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from indicnlp.normalize import indic_normalize\n",
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import transliterate\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NLLB = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer_nllb = AutoTokenizer.from_pretrained(MODEL_NLLB)\n",
        "model_nllb = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NLLB).to(DEVICE)\n",
        "\n",
        "LANG_CONFIG = {\n",
        "    \"hindi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"mujhe class ke baad meeting me aana hai\": \"‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ï‡•ç‡§∑‡§æ ‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§¨‡•à‡§†‡§ï ‡§Æ‡•á‡§Ç ‡§Ü‡§®‡§æ ‡§π‡•à\",\n",
        "            \"class\": \"‡§ï‡§ï‡•ç‡§∑‡§æ\", \"meeting\": \"‡§¨‡•à‡§†‡§ï\", \"me\": \"‡§Æ‡•á‡§Ç\", \"after\": \"‡§¨‡§æ‡§¶\", \"ke\": \"‡§ï‡•á\", \"baad\": \"‡§¨‡§æ‡§¶\",\n",
        "            \"aana\": \"‡§Ü‡§®‡§æ\", \"hai\": \"‡§π‡•à\", \"mujhe\": \"‡§Æ‡•Å‡§ù‡•á\", \"please\": \"‡§ï‡•É‡§™‡§Ø‡§æ\", \"sir\": \"‡§∏‡§æ‡§π‡§¨\", \"madam\": \"‡§Æ‡•à‡§°‡§Æ\",\n",
        "            \"office\": \"‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø\", \"wifi\": \"‡§µ‡§æ‡§à-‡§´‡§æ‡§à\", \"signal\": \"‡§∏‡§Ç‡§ï‡•á‡§§\", \"weak\": \"‡§ï‡§Æ‡§ú‡§º‡•ã‡§∞\", \"valare\": \"‡§¨‡§π‡•Å‡§§\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"hin_Deva\",\n",
        "        \"normalizer\": \"hi\"\n",
        "    },\n",
        "    \"tamil\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"naan class ku poganum\": \"‡Æ®‡Ææ‡Æ©‡Øç ‡Æµ‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"wifi signal\": \"‡Æµ‡Øà‡ÆÉ‡Æ™‡Øà ‡Æö‡Æø‡Æï‡Øç‡Æ©‡Æ≤‡Øç\", \"valare\": \"‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç\", \"weak\": \"‡Æµ‡ØÄ‡Æï‡Øç\", \"aanu\": \"‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ\",\n",
        "            \"naan\": \"‡Æ®‡Ææ‡Æ©‡Øç\", \"class\": \"‡Æï‡Æø‡Æ≥‡Ææ‡Æ∏‡Øç\", \"ku\": \"‡Æï‡Øç‡Æï‡ØÅ\", \"poganum\": \"‡Æ™‡Øã‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"ponanum\": \"‡Æ™‡Øã‡Æµ‡Øá‡Æ©‡Øç\", \"varanum\": \"‡Æµ‡Æ∞‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"sollanum\": \"‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡Æ£‡ØÅ‡ÆÆ‡Øç\", \"pananum\": \"‡Æ™‡Æ£‡Æ£‡ØÅ‡ÆÆ‡Øç\",\n",
        "            \"office\": \"‡ÆÖ‡Æ≤‡ØÅ‡Æµ‡Æ≤‡Æï‡ÆÆ‡Øç\", \"signal\": \"‡Æö‡Æø‡Æï‡Øç‡Æ©‡Æ≤‡Øç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TAMIL,\n",
        "        \"lang_code_nllb\": \"tam_Taml\",\n",
        "        \"normalizer\": \"ta\"\n",
        "    },\n",
        "    \"telugu\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"wifi signal\": \"‡∞µ‡±à‡∞´‡±à ‡∞∏‡∞ø‡∞ó‡±ç‡∞®‡∞≤‡±ç\", \"valare\": \"‡∞ö‡∞æ‡∞≤‡∞æ\", \"weak\": \"‡∞µ‡±Ä‡∞ï‡±ç\", \"aanu\": \"‡∞â‡∞Ç‡∞¶‡∞ø\",\n",
        "            \"class\": \"‡∞§‡∞∞‡∞ó‡∞§‡∞ø\", \"vellali\": \"‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞ø\", \"office\": \"‡∞Ü‡∞´‡±Ä‡∞∏‡±ç\", \"wifi\": \"‡∞µ‡±à‡∞´‡±à\", \"signal\": \"‡∞∏‡∞ø‡∞ó‡±ç‡∞®‡∞≤‡±ç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.TELUGU,\n",
        "        \"lang_code_nllb\": \"tel_Telu\",\n",
        "        \"normalizer\": \"te\"\n",
        "    },\n",
        "    \"marathi\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"wifi signal\": \"‡§µ‡§æ‡§à-‡§´‡§æ‡§à ‡§∏‡§ø‡§ó‡•ç‡§®‡§≤\", \"valare\": \"‡§´‡§æ‡§∞\", \"weak\": \"‡§ï‡§Æ‡§ú‡•ã‡§∞\", \"aanu\": \"‡§Ü‡§π‡•á\",\n",
        "            \"tu\": \"‡§§‡•Ç\", \"tula\": \"‡§§‡•Å‡§≤‡§æ\", \"kasa\": \"‡§ï‡§∏‡§æ\", \"majha\": \"‡§Æ‡§æ‡§ù‡§æ\", \"office\": \"‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø\",\n",
        "            \"wifi\": \"‡§µ‡§æ‡§à-‡§´‡§æ‡§à\", \"school\": \"‡§∂‡§æ‡§≥‡§æ\", \"nahi\": \"‡§®‡§æ‡§π‡•Ä\", \"signal\": \"‡§∏‡§ø‡§ó‡•ç‡§®‡§≤\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.DEVANAGARI,\n",
        "        \"lang_code_nllb\": \"mar_Deva\",\n",
        "        \"normalizer\": \"mr\"\n",
        "    },\n",
        "    \"bengali\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"wifi signal\": \"‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á ‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤\", \"valare\": \"‡¶ñ‡ßÅ‡¶¨\", \"weak\": \"‡¶¶‡ßÅ‡¶∞‡ßç‡¶¨‡¶≤\", \"aanu\": \"‡¶Ü‡¶õ‡ßá\",\n",
        "            \"ami\": \"‡¶Ü‡¶Æ‡¶ø\", \"tumi\": \"‡¶§‡ßÅ‡¶Æ‡¶ø\", \"office\": \"‡¶Ö‡¶´‡¶ø‡¶∏\", \"wifi\": \"‡¶ì‡¶Ø‡¶º‡¶æ‡¶á‡¶´‡¶æ‡¶á\", \"signal\": \"‡¶∏‡¶ø‡¶ó‡¶®‡ßç‡¶Ø‡¶æ‡¶≤\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.BENGALI,\n",
        "        \"lang_code_nllb\": \"ben_Beng\",\n",
        "        \"normalizer\": \"bn\"\n",
        "    },\n",
        "    \"malayalam\": {\n",
        "        \"code_mix_dict\": {\n",
        "            \"wifi signal\": \"‡¥µ‡µà‡¥´‡µà ‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ\", \"valare\": \"‡¥µ‡¥≥‡¥∞‡µÜ\", \"weak\": \"‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡µç\", \"aanu\": \"‡¥Ü‡¥£‡µç\",\n",
        "            \"nee\": \"‡¥®‡µÄ\", \"lunch\": \"‡¥≤‡¥û‡µç‡¥ö‡µç\", \"signal\": \"‡¥∏‡¥ø‡¥ó‡µç‡¥®‡µΩ\", \"wifi\": \"‡¥µ‡µà‡¥´‡µà\", \"office\": \"‡¥ì‡¥´‡µÄ‡¥∏‡µç\",\n",
        "            \"week\": \"‡¥µ‡µÄ‡¥ï‡µç‡¥ï‡µç\"\n",
        "        },\n",
        "        \"src_script\": sanscript.ITRANS,\n",
        "        \"tgt_script\": sanscript.MALAYALAM,\n",
        "        \"lang_code_nllb\": \"mal_Mlym\",\n",
        "        \"normalizer\": \"ml\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def phrase_code_mix(text, lang):\n",
        "    config = LANG_CONFIG[lang]\n",
        "    tokens = text.split()\n",
        "    result = []\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        matched = False\n",
        "        for length in range(4, 0, -1):\n",
        "            if i+length <= len(tokens):\n",
        "                phrase = \" \".join(tokens[i:i+length]).lower()\n",
        "                if phrase in config[\"code_mix_dict\"]:\n",
        "                    result.append(config[\"code_mix_dict\"][phrase])\n",
        "                    i += length\n",
        "                    matched = True\n",
        "                    break\n",
        "        if not matched:\n",
        "            token = tokens[i]\n",
        "            if token.lower() in config[\"code_mix_dict\"]:\n",
        "                result.append(config[\"code_mix_dict\"][token.lower()])\n",
        "            else:\n",
        "                # Native transliteration for unmapped roman tokens except Malayalam (leave roman)\n",
        "                if lang == \"malayalam\":\n",
        "                    result.append(token)\n",
        "                else:\n",
        "                    try:\n",
        "                        native = transliterate(token, config[\"src_script\"], config[\"tgt_script\"])\n",
        "                        result.append(native if not re.search(r\"[A-Za-z]\", native) else token)\n",
        "                    except Exception:\n",
        "                        result.append(token)\n",
        "            i += 1\n",
        "    return \" \".join(result)\n",
        "\n",
        "def normalize_native_text(text, lang):\n",
        "    normalizer = indic_normalize.IndicNormalizerFactory().get_normalizer(LANG_CONFIG[lang][\"normalizer\"])\n",
        "    norm = normalizer.normalize(text)\n",
        "    if lang == \"hindi\":\n",
        "        norm = norm.replace(\"‡§ï‡•ç‡§≤‡§æ‡§∏\", \"‡§ï‡§ï‡•ç‡§∑‡§æ\").replace(\"‡§Æ‡•Ä‡§ü‡§ø‡§Ç‡§ó\", \"‡§¨‡•à‡§†‡§ï\")\n",
        "    elif lang == \"bengali\":\n",
        "        norm = norm.replace(\"‡¶≠‡¶æ‡¶≤\", \"‡¶≠‡¶æ‡¶≤‡ßã\")\n",
        "    elif lang == \"marathi\":\n",
        "        norm = norm.replace(\"‡§õ‡•ç‡§π‡§æ‡§®\", \"‡§õ‡§æ‡§®\").replace(\"\\u200c\", \"\").replace(\"\\u200b\", \"\")\n",
        "    return re.sub(r\"\\s+\", \" \", norm).strip()\n",
        "\n",
        "def translate_nllb(text, src_code, tgt_code):\n",
        "    tokenizer_nllb.src_lang = src_code\n",
        "    encoded = tokenizer_nllb(text, return_tensors=\"pt\").to(DEVICE)\n",
        "    tgt_id = tokenizer_nllb.convert_tokens_to_ids(tgt_code)\n",
        "    out = model_nllb.generate(**encoded, forced_bos_token_id=tgt_id)\n",
        "    return tokenizer_nllb.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "def full_pipeline(input_text, input_lang, target_langs):\n",
        "    print(f\"\\n[INFO] Input: {input_text}\")\n",
        "    # Malayalam romanization clean up (if needed)\n",
        "    if input_lang == \"malayalam\":\n",
        "        input_text = input_text.lower().strip()\n",
        "    # Step 1: Code-mixed phrase mapping and fallback transliteration\n",
        "    native = phrase_code_mix(input_text, input_lang)\n",
        "    print(f\"[INFO] Native script after mapping: {native}\")\n",
        "    # Step 2: Normalization\n",
        "    normalized = normalize_native_text(native, input_lang)\n",
        "    print(f\"[INFO] Normalized: {normalized}\")\n",
        "    # Step 3: Native -> English\n",
        "    english = translate_nllb(normalized, LANG_CONFIG[input_lang]['lang_code_nllb'], \"eng_Latn\")\n",
        "    print(f\"[INFO] English: {english}\")\n",
        "    translations = {LANG_CONFIG[input_lang]['lang_code_nllb']: normalized, \"eng_Latn\": english}\n",
        "    # Step 4: English -> others\n",
        "    print(\"[INFO] Other languages:\")\n",
        "    for lang in target_langs:\n",
        "        code = LANG_CONFIG[lang]['lang_code_nllb']\n",
        "        pred = translate_nllb(english, \"eng_Latn\", code)\n",
        "        translations[code] = pred\n",
        "        print(f\"{lang}: {pred}\")\n",
        "    print(\"[INFO] Pipeline complete\")\n",
        "    return translations\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example: Try various code-mixed or roman/colloquial inputs in any language\n",
        "    INPUT_SENTENCE = \"ami ajke onek kaaj niye busy achhi.\"\n",
        "    INPUT_LANG = \"bengali\"\n",
        "    TARGET_LANGUAGES = [\"hindi\", \"tamil\", \"telugu\", \"marathi\", \"malayalam\"]\n",
        "    results = full_pipeline(INPUT_SENTENCE, INPUT_LANG, TARGET_LANGUAGES)\n",
        "\n",
        "    # Try code-mixed Hindi:\n",
        "    # INPUT_SENTENCE = \"mujhe class ke baad meeting me aana hai\"\n",
        "    # INPUT_LANG = \"hindi\"\n",
        "    # ...and so on for other languages.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tq_BAhkZcr3r",
        "outputId": "273a575f-7b84-4e48-ff69-b0e7128badf7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Input: ami ajke onek kaaj niye busy achhi.\n",
            "[INFO] Native script after mapping: ‡¶Ü‡¶Æ‡¶ø ‡¶Ö‡¶ú‡ßç‡¶ï‡ßá ‡¶ì‡¶®‡ßá‡¶ï‡ßç ‡¶ï‡¶æ‡¶ú‡ßç ‡¶®‡¶ø‡¶Ø‡ßá ‡¶¨‡ßÅ‡¶∏‡ßç‡¶Ø‡ßç ‡¶Ö‡¶õ‡¶ø‡•§\n",
            "[INFO] Normalized: ‡¶Ü‡¶Æ‡¶ø ‡¶Ö‡¶ú‡ßç‡¶ï‡ßá ‡¶ì‡¶®‡ßá‡¶ï‡ßç ‡¶ï‡¶æ‡¶ú‡ßç ‡¶®‡¶ø‡¶Ø‡ßá ‡¶¨‡ßÅ‡¶∏‡ßç‡¶Ø‡ßç ‡¶Ö‡¶õ‡¶ø‡•§\n",
            "[INFO] English: I'm going to take that shit.\n",
            "[INFO] Other languages:\n",
            "hindi: ‡§Æ‡•à‡§Ç ‡§â‡§∏ ‡§¨‡§ï‡§µ‡§æ‡§∏ ‡§≤‡•á ‡§ú‡§æ‡§è‡§ó‡§æ.\n",
            "tamil: ‡Æ®‡Ææ‡Æ©‡Øç ‡ÆÖ‡Æ®‡Øç‡Æ§ ‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡Øà ‡Æé‡Æü‡ØÅ‡Æï‡Øç‡Æï ‡Æ™‡Øã‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç.\n",
            "telugu: ‡∞®‡±á‡∞®‡±Å ‡∞Ü shit ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡∞ø.\n",
            "marathi: ‡§Æ‡•Ä ‡§§‡•ç‡§Ø‡§æ ‡§ó‡•ã‡§∑‡•ç‡§ü‡•Ä ‡§∏‡•ç‡§µ‡•Ä‡§ï‡§æ‡§∞‡§£‡§æ‡§∞ ‡§Ü‡§π‡•á.\n",
            "malayalam: ‡¥û‡¥æ‡µª ‡¥Ü ‡¥Æ‡¥£‡µç‡¥ü‡¥§‡µç‡¥§‡¥∞‡¥ô‡µç‡¥ô‡µæ ‡¥∏‡µç‡¥µ‡µÄ‡¥ï‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥™‡µã‡¥µ‡µÅ‡¥ï‡¥Ø‡¥æ‡¥£‡µç.\n",
            "[INFO] Pipeline complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pl56Q8MB4Ki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}